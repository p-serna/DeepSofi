{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/bssn/serna/environments/deepl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import matplotlib.pylab as plt\n",
    "import sys,os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9412401566986668679\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7486465818198468804\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4083183977622375147\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7899945370\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6312452902868181266\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:05:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of synthetic data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f11b00c1828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAEyCAYAAAC1RdmaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGDNJREFUeJzt3X2MXfWd3/H31+PxjDEGbHC8js1jQkJ3aTDpxNlV6JYQgdhoK4i0QkHbiFRpnUiLlCjRKtmoKtmqkVC0CaVqxNYJ3hDlwUEkFCtlCTTLikWqCAM4xDyEEmOCHePBax5swA8z/vaPe0zGzv2Nx8b3d4Y775c0mnt/33Pu+fowl/nMOed3T2QmkiRJNcxpuwFJkjR7GDwkSVI1Bg9JklSNwUOSJFVj8JAkSdUYPCRJUjUGD0mSVI3BQ5IkVWPwkCRJ1cxtuwFJvRURlwM3AgPANzPz+tKy82Ioh1lQrTdJ/WMXL+7IzCVHWs7gIfWxiBgAvg5cCmwBHoyI9Zn5eLflh1nA++NDNVuU1Cf+T9727HSW81SL1N9WAU9n5qbM3AesA65ouSdJs5jBQ+pvy4HnJj3f0oy9ISJWR8RoRIzuZ2/V5iTNPgYPaZbLzDWZOZKZI4MMtd2OpD5n8JD621bg9EnPVzRjktQKg4fU3x4Ezo2IsyNiHvBRYH3LPUmaxZzVIvWxzByPiGuBn9CZTrs2Mx9ruS1Js5jBQ+pzmXkncGfbfUgSeKpFkiRVZPCQJEnVGDwkSVI1Bg9JklSNwUOSJFXjrBZJkma6iHJp7mB5vTnl9YomJoqlnKJGTu/lPeIhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqpxVoskSTNAzC3/Sp6zaFGxlstOLdYmFgyVt5fdp6EMvPhacR22v1CuvVguTeYRD0mSVI3BQ5IkVWPwkCRJ1Rg8JElSNQYPSZJUjcFDkiRV43RaSZJmgDknnFCs7f2XZxRrv/nX5Smze1bsL29wovsN5E765YnFVd5+77zy6zmdVpIkzTQGD0mSVI3BQ5IkVWPwkCRJ1Rg8JElSNQYPSZJUjdNppT4XEZuBXcAEMJ6ZI+121Cei+1REgJg72H184Nj+1svCXUQBct++qVY8pu2px0o/O/OHi6u8fE55GuuZ/+bZYu2zZ9xdrO2c6D5t9j+f8m+L67z+ywXFGo+US5MZPKTZ4YOZuaPtJiTJUy2SJKkag4fU/xK4OyIeiojVhxcjYnVEjEbE6H72ttCepNnEUy1S/7soM7dGxNuAeyLiycy872AxM9cAawBOisVeFCCppzziIfW5zNzafB8DbgdWtduRpNnM4CH1sYhYEBELDz4GLgM2ttuVpNnMUy1Sf1sK3B6d6Xtzge9l5l3ttvQWMsWU2YHTTivW9r97edfxvadOcWfPKQy9VL7D6LynthVr49tf6F44MHFMfai3Yk75WMDEUPln8Z0LyxPW3j/8SrG2c6L77WQXn/TaFH3ML9amy+Ah9bHM3ARc0HYfknSQp1okSVI1Bg9JklSNwUOSJFVj8JAkSdUYPCRJUjXOapGkgtJdZqE8ZRbg6T/vPm32gt8v30V0Thwo1h55+sxi7ex1K4q1oRdf6jp+YI/TaWeiHC//dxncXf5Q4Z+NnVGsfWfBu4q1l8dP6Do+NnZycZ0zX3vzPzse8ZAkSdUYPCRJUjUGD0mSVI3BQ5IkVWPwkCRJ1TirRZIKYqD8t9ne08o3fLvwD57pOv6dc/53cZ3BGCjWPj3/A8Xawz9dWawNDZRfUy3K7jNU8rXyzdkW/fLVYm37XUuKtf++9E+LtZjofuO5054pz6CZv7lw48Gj4BEPSZJUjcFDkiRVY/CQJEnVGDwkSVI1Bg9JklSNwUOSJFXjdFpJOgYZ3aciAsyd0/2Gb1NNmZ2qNjemuDFXuQ2Y49+WbyUHXt9TrA08vrlYW/78KcVaDpWnfZem9cZr5T4O7Hyx/HrT5E+lJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqpxOq3UByJiLfCnwFhmnt+MLQZ+AJwFbAauysw3PxduFsnCdEOAoZf2F2ujT5/Vdfxzw39YXGdOlLd119P/olh7+84pptpOTFHTzHOg/N9rYteu8nq7y3euPSbZfTp4p1b+OZ0uj3hI/eFbwOWHjX0B+Glmngv8tHkuSa0yeEh9IDPvA3YeNnwFcEvz+BbgyqpNSVIXnmqR+tfSzNzWPH4eWNptoYhYDawGGOaESq1Jmq084iHNAtm5WKHrydnMXJOZI5k5MshQ5c4kzTYGD6l/bY+IZQDN97GW+5Ekg4fUx9YD1zSPrwHuaLEXSQK8xkPqCxHxfeBi4LSI2AJcB1wP3BoRnwCeBa5qr8O3ptw/XqwNPfV8sXbmuuVdxx9YMnJMfbx9Z7mPBY+V+xjfs/eYtqcZaKpprPnWmjZt8JD6QGZeXSh9qGojknQEnmqRJEnVGDwkSVI1Bg9JklSNwUOSJFVj8JAkSdU4q0WSSqa4W+j4tu3F2vA/H37bnGZ8cPDY+pjiLrNTTpmdon+pLR7xkCRJ1Rg8JElSNQYPSZJUjcFDkiRVY/CQJEnVOKtFko7FFDNGDuwp1Pbs6VEz0luHRzwkSVI1Bg9JklSNwUOSJFVj8JAkSdUYPCRJUjUGD0mSVI3BQ5IkVWPwkCRJ1Rg8JElSNQYPSZJUjcFDkiRVY/CQJEnVGDwkSVI1Bg+pD0TE2ogYi4iNk8a+FBFbI2JD8/XhNnuUJDB4SP3iW8DlXcZvyMyVzdedlXuSpN9h8JD6QGbeB+xsuw9JOhKDh9Tfro2IR5tTMYu6LRARqyNiNCJG97O3dn+SZhmDh9S/bgLeAawEtgFf7bZQZq7JzJHMHBlkqGZ/kmYhg4fUpzJze2ZOZOYB4BvAqrZ7kiSDh9SnImLZpKcfATaWlpWkWua23YCkNy8ivg9cDJwWEVuA64CLI2IlkMBm4JOtNShJDYOH1Acy8+ouwzdXb0SSjsBTLZIkqRqDhyRJqsbgIUmSqjF4SJKkagwekiSpGoOHJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqjF4SJKkagwekiSpGoOHJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqoxeEiSpGoMHpIkqZq501koIi4HbgQGgG9m5vVTLT84b0EODy/qXpwi6uScKDRQXmd8eIo+dmWxdmCw/KJZ6HHo1D3Fdfa8VG5kz/YtOzJzSXEB6U2KiNOBbwNLgQTWZOaNEbEY+AFwFrAZuCozX2yrT0k6YvCIiAHg68ClwBbgwYhYn5mPl9YZHl7Ev/rDa7vWJoYHituaGOoeBqYKCS+eV04yy+7fW6y9tnSwWBuf331753z8qeI6T9zx7mLt8a989tliUTo+xoHPZebDEbEQeCgi7gE+Dvw0M6+PiC8AXwA+32Kfkma56ZxqWQU8nZmbMnMfsA64ordtSToambktMx9uHu8CngCW03mv3tIsdgtwZTsdSlLHdILHcuC5Sc+3NGOHiIjVETEaEaP79796vPqTdJQi4izgQuABYGlmbmtKz9M5FXP48r9971I+SihJx8Nxu7g0M9dk5khmjgwOLjheLyvpKETEicAPgc9k5iuTa5mZdK7/4LDx3753GarUqaTZajrBYytw+qTnK5oxSTNIRAzSCR3fzcwfNcPbI2JZU18GjLXVnyTB9ILHg8C5EXF2RMwDPgqs721bko5GRARwM/BEZn5tUmk9cE3z+Brgjtq9SdJkR5zVkpnjEXEt8BM602nXZuZjU60zfkKw44Luh2z3nVye4jq4q/tsklf/oHzeeeU5vy7WHnn7WcXau//nrmLt1x8+uev48MD+4jr//pq7irW//EqxJB0vHwA+BvwiIjY0Y18ErgdujYhPAM8CV7XUnyQB0/wcj8y8E7izx71IOkaZeT/lT7z5UM1eJGkqfnKpJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSapmWrNajtbAPlj43IGutd+cX56Suq9wTf6my24urnPr7u5TXwGeefHUYu2f31O4ey7lu9PuO9CT3SVJ0qzhEQ9JklSNwUOSJFVj8JAkSdUYPCRJUjUGD0mSVE3PpmlkYYZKvDJYXumUfV2Hv7urPDvl/77yzmJtz0OLi7V5J5XbOOmZ7jeye+o77y6u88D7zim/IHdPUZMkafbwiIckSarG4CFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqunJdNo5+w6w8JlXu9bm75hXXG/H+cNdx//T/o8U1znxyfLrzS1M6QUY3N19yizAyb96vev460uHiusM/FN5mvCvy21IkjSreMRDkiRVY/CQJEnVGDwkSVI1Bg9JklSNwUOSJFVj8JAkSdVMazptRGwGdgETwHhmjky5/MQBBl7uPiV1KieMdZ+S+nv/YbS4zutXrCrW5r08XqztPK88NTYL83BP+E353/T8+xcUa1IvRcTpwLeBpUACazLzxoj4EvAfgReaRb+YmXe206UkdRzN53h8MDN39KwTScdqHPhcZj4cEQuBhyLinqZ2Q2b+TYu9SdIhevIBYpLqycxtwLbm8a6IeAJY3m5XktTddK/xSODuiHgoIlZ3WyAiVkfEaESM7ht/7fh1KGnaIuIs4ELggWbo2oh4NCLWRsSiwjpvvHf3s7dSp5Jmq+kGj4sy873AnwB/ERF/fPgCmbkmM0cyc2Te3BOOa5OSjiwiTgR+CHwmM18BbgLeAaykc0Tkq93Wm/zeHaR87ZMkHQ/TCh6ZubX5PgbcDpSv6JRUXUQM0gkd383MHwFk5vbMnMjMA8A38H0raQY4YvCIiAXNBWtExALgMmBjrxuTND0REcDNwBOZ+bVJ48smLfYRfN9KmgGmc3HpUuD2zv/bmAt8LzPvmnKNffvJ537TtbTpuncVVzvpH7tPYx34/fI6g7smirWhX+8s1n5vrHxX29fPOLn7+IryYeh3fv/lYm1TsSIdFx8APgb8IiI2NGNfBK6OiJV0rtHaDHyynfYk6beOGDwycxNwQYVeJB2DzLwf6Jba/cwOSTOOn1wqSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqrpzb1aBuYw56SFXUtn/48srpaDe7qO719c/iTUPaeW/wnDvypPtWV/+c61WYhj+xZ2n+4LsPuc7v9eAB4plyRJmk084iFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqunJrJYD8+fx+ntO71qbmFfOOids2d11fPfZ5RkjexaVX2/PO95WrHW9s0Vj3ov7uo6/bez14jovvHeKWS2SJAnwiIckSarI4CFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqunJdNo5+yYY3rqra23Xu04pr7d9Z9fxPReeXFxnwVj5RnB7F5f/eVNNw128sfsN5F49Y0Fxnf0nTjE/V5IkAR7xkCRJFRk8JElSNQYPSZJUjcFDkiRVY/CQJEnVGDwkSVI1PZlO+8qe53f8ZOOXn22engbseKO48RhecO3x6OqwPuo6s6XtapaIiGHgPmCIzvv6tsy8LiLOBtYBpwIPAR/LzO63X5akCnoSPDJzycHHETGamSO92M7RmCl9SD2yF7gkM3dHxCBwf0T8PfBZ4IbMXBcRfwt8AripzUYlzW6eapH6QHbsbp4ONl8JXALc1ozfAlzZQnuS9AaDh9QnImIgIjYAY8A9wK+AlzLz4EfxbgGWd1lvdUSMRsTofvbWa1jSrFQjeKypsI3pmCl9SD2RmROZuRJYAawCzpvmemsycyQzRwYZ6mmPktTz4JGZM+IX/kzpQ+q1zHwJuBf4I+CUiDh4LdcKYGtrjUkSnmqR+kJELImIU5rH84FLgSfoBJA/axa7BrijnQ4lqaMns1okVbcMuCUiBuj8QXFrZv44Ih4H1kXEfwUeAW5us0lJ6lnwiIjLgRuBAeCbmXl9r7Y1jV42A7uACWDcabXqN5n5KHBhl/FNdK73kKQZoSfBo/mr6+t0DvduAR6MiPWZ+XgvtjdNH8zMtj5ATJIk0btrPFYBT2fmpuZTEtcBV/RoW5Ik6S2iV8FjOfDcpOddPz+gogTujoiHImJ1i31IkjSrzZaLSy/KzK0R8Tbgnoh4MjPva7spSZJmm14d8dgKnD7peaufH5CZW5vvY8DteLGdJEmt6FXweBA4NyLOjoh5wEeB9T3a1pQiYkFELDz4GLiMY7tHriRJepN6dXfa8Yi4FvgJnem0azPzsV5saxqWArdHBHT+vd/LzLta6kWSpFmtZ9d4ZOadwJ29ev2j6GMTcEHbfUiSJD8yXZIkVWTwkCRJ1Rg8JElSNQYPSZJUjcFDkiRVY/CQJEnVGDwkSVI1Bg9JklSNwUOSJFVj8JAkSdUYPCRJUjUGD0mSVI3BQ5IkVWPwkCRJ1Rg8JElSNQYPSZJUjcFDkiRVY/CQ+kBEDEfEzyLi5xHxWET8dTP+rYh4JiI2NF8r2+5V0uw2t+0GJB0Xe4FLMnN3RAwC90fE3ze1v8zM21rsTZLeYPCQ+kBmJrC7eTrYfGV7HUlSd55qkfpERAxExAZgDLgnMx9oSl+OiEcj4oaIGOqy3uqIGI2I0f3srdqzpNnH4CH1icycyMyVwApgVUScD/wVcB7wPmAx8Pku663JzJHMHBnkd3KJJB1XBg+pz2TmS8C9wOWZuS079gJ/B6xqtztJs53BQ+oDEbEkIk5pHs8HLgWejIhlzVgAVwIb2+tSkry4VOoXy4BbImKAzh8Ut2bmjyPiHyJiCRDABuBTbTYpSQYPqQ9k5qPAhV3GL2mhHUkq8lSLJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqjF4SJKkagwekiSpGoOHJEmqxuAhSZKqMXhIkqRqDB6SJKkag4ckSarG4CFJkqoxeEiSpGoMHpIkqRqDhyRJqsbgIUmSqjF4SJKkagwekiSpGoOHJEmqJjKz7R4kzRAR8QLw7KSh04AdLbUzmX0cyj4OZR+HaquPMzNzyZEWMnhIKoqI0cwcsQ/7sA/7OF481SJJkqoxeEiSpGoMHpKmsqbtBhr2cSj7OJR9HGqm9NGV13hIkqRqPOIhSZKqMXhIkqRqDB6SfkdEXB4Rv4yIpyPiCy32sTkifhERGyJitPK210bEWERsnDS2OCLuiYj/13xf1EIPX4qIrc0+2RARH+5lD802T4+IeyPi8Yh4LCI+3YzX3h+lPqruk4gYjoifRcTPmz7+uhk/OyIeaN43P4iIeS318a2IeGbS/ljZyz6Oltd4SDpERAwATwGXAluAB4GrM/PxFnrZDIxkZvUPQ4qIPwZ2A9/OzPObsa8AOzPz+iaQLcrMz1fu4UvA7sz8m15tt0sfy4BlmflwRCwEHgKuBD5O3f1R6uMqKu6TiAhgQWbujohB4H7g08BngR9l5rqI+Fvg55l5Uwt9fAr4cWbe1qttvxke8ZB0uFXA05m5KTP3AeuAK1ruqbrMvA/YedjwFcAtzeNb6PzSq91DdZm5LTMfbh7vAp4AllN/f5T6qCo7djdPB5uvBC4BDv6yr7E/Sn3MaAYPSYdbDjw36fkWWvifeyOBuyPioYhY3VIPky3NzG3N4+eBpS31cW1EPNqciunp6Y3DRcRZwIXAA7S4Pw7rAyrvk4gYiIgNwBhwD/Ar4KXMHG8WqfK+ObyPzDy4P77c7I8bImKo130cDYOHpJnsosx8L/AnwF80px5mhOycp27jr8ubgHcAK4FtwFdrbTgiTgR+CHwmM1+ZXKu5P7r0UX2fZOZEZq4EVtA5Snher7c5nT4i4nzgr5p+3gcsBnp2+utYGDwkHW4rcPqk5yuaseoyc2vzfQy4nc7/4Nu0vbnO4OD1BmO1G8jM7c0vmwPAN6i0T5prCH4IfDczf9QMV98f3fpoa580234JuBf4I+CUiJjblKq+byb1cXlzSiozcy/wd7T/vjmEwUPS4R4Ezm2u0J8HfBRYX7uJiFjQXEBIRCwALgM2Tr1Wz60HrmkeXwPcUbuBg7/oGx+hwj5pLmK8GXgiM782qVR1f5T6qL1PImJJRJzSPJ5P50LsJ+j84v+zZrEa+6NbH09OCoNB5zqTtt83h3BWi6Tf0UxH/G/AALA2M7/cQg/n0DnKATAX+F7NPiLi+8DFdG4xvh24DvhfwK3AGcCzwFWZ2bOLPws9XEznlEICm4FPTrrOold9XAT8E/AL4EAz/EU611fU3B+lPq6m4j6JiPfQuXh0gM4f8Ldm5n9pfmbX0Tm98Qjw75qjDrX7+AdgCRDABuBTky5CbZ3BQ5IkVeOpFkmSVI3BQ5IkVWPwkCRJ1Rg8JElSNQYPSZJUjcFDkiRVY/CQJEnV/H9VUai082tzjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14,5))\n",
    "gs = mpl.gridspec.GridSpec(4, 8 , wspace=0., hspace=0.) # 2x3 grid\n",
    "\n",
    "ax0 = fig.add_subplot(gs[2,2]) # first full col\n",
    "ax1 = fig.add_subplot(gs[:,4:]) # first row, second col\n",
    "ax0.imshow(Ft.mean(axis=-1))\n",
    "ax1.imshow(Ot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "home = \"/export/home1/users/bssn/serna\"\n",
    "datadir = home+\"/SyntheticData/syndat/\"\n",
    "#os.listdir(datadir)\n",
    "i = randint(0,900)\n",
    "Ft = np.load(datadir+\"d\"+str(i).zfill(4)+\".npy\")\n",
    "Ot4 = np.load(datadir+\"o4_\"+str(i).zfill(4)+\".npy\")\n",
    "fig,ax = plt.subplots(1,2,figsize=(14,5))\n",
    "ax[0].imshow(Ft.mean(axis=-1))\n",
    "ax[1].imshow(Ot4)\n",
    "width,height,T = Ft.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483595543633605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ot4.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_time_segment(segment_frames,total_frames=12000):\n",
    "    '''\n",
    "    Gets a random time segment of duration segment_frames in a file\n",
    "    with number of frames: total_frames\n",
    "    '''\n",
    "    \n",
    "    segment_start = randint(0, high = total_frames-\n",
    "                                   segment_frames)\n",
    "    segment_end = segment_start + segment_frames\n",
    "    \n",
    "    return (segment_start, segment_end)\n",
    "\n",
    "def readdata(nframes,i0=0,n=800,magn=2,repeat = 4):\n",
    "\n",
    "    X = np.zeros((n*repeat,width,height,nframes))\n",
    "    Y = np.zeros((n*repeat,width*magn,height*magn))\n",
    "    j = 0\n",
    "    for i in range(i0,i0+n):\n",
    "        xt = np.load(datadir+\"d\"+str(i).zfill(4)+\".npy\")\n",
    "        yt = np.load(datadir+\"o\"+str(magn)+\"_\"+str(i).zfill(4)+\".npy\") \n",
    "        xt = xt/xt.max()\n",
    "        ymax = max(1,yt.max())\n",
    "        # This is to avoid 0s in pictures without blinking spots, \n",
    "        # but it may give us problems, most likely\n",
    "        for ir in range(repeat):\n",
    "            start,end = get_random_time_segment(nframes,T)\n",
    "            X[j,:,:,:] = xt[:,:,start:end]\n",
    "            Y[j,:,:] = yt/ymax\n",
    "            j = j+1\n",
    "    X = np.reshape(X,(X.shape[0],X.shape[1],X.shape[2],X.shape[3],1))\n",
    "    #Y = reshape(Y,(Y.shape[0],Y.shape[1],Y.shape[2],1,1))\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,Y training data shapes: (3200, 10, 10, 100, 1) (3200, 40, 40)\n",
      "X,Y validation data shapes: (100, 10, 10, 100, 1) (100, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "nframes = 100\n",
    "X,Y = readdata(nframes,n=800,magn=4,repeat = 4)\n",
    "print('X,Y training data shapes:',X.shape,Y.shape)\n",
    "\n",
    "Xdev,Ydev = readdata(nframes,i0=800,n=100,magn=4,repeat =1)\n",
    "print('X,Y validation data shapes:',Xdev.shape,Ydev.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Mendel ...? Loss function\n",
    "def MOC(y_true,y_pred):\n",
    "    '''Just another crossentropy'''\n",
    "    ly = K.sum(y_true*y_pred)\n",
    "    ly2 = K.sum(y_pred*y_pred)\n",
    "    ly3 = K.sum(y_true*y_true)\n",
    "    out = ly/K.sqrt(ly2*ly3)\n",
    "    return out\n",
    "def PCCl(y_true,y_pred):\n",
    "    '''Just another crossentropy'''\n",
    "    lt1 = y_true-K.mean(y_true)\n",
    "    lt2 = y_pred-K.mean(y_pred)\n",
    "    \n",
    "    ly = K.sum(lt1*lt2)\n",
    "    ly2 = K.sum(lt1*lt1)\n",
    "    ly3 = K.sum(lt2*lt2)\n",
    "    out = ly/K.sqrt(ly2*ly3)\n",
    "    \n",
    "    return 1.0-out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_69 (Conv3D)           (None, 10, 10, 100, 16)   736       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_69 (MaxPooling (None, 10, 10, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 10, 10, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_70 (Conv3D)           (None, 10, 10, 25, 32)    23072     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_70 (MaxPooling (None, 5, 5, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 5, 5, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_71 (Conv3D)           (None, 5, 5, 6, 128)      184448    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_71 (MaxPooling (None, 2, 2, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1600)              411200    \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 40, 40)            0         \n",
      "=================================================================\n",
      "Total params: 750,784\n",
      "Trainable params: 750,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv3D(16, (3,3,5),padding='same', activation = 'relu', input_shape = (width,height,nframes,1)),\n",
    "tf.keras.layers.MaxPooling3D(pool_size=(1,1,4)),\n",
    "tf.keras.layers.Dropout(0.1),\n",
    "tf.keras.layers.Conv3D(32, (3,3,5),padding='same', activation = 'relu'),\n",
    "tf.keras.layers.MaxPooling3D(pool_size=(2,2,4)),\n",
    "tf.keras.layers.Dropout(0.1),\n",
    "tf.keras.layers.Conv3D(128, (3,3,5),padding='same', activation = 'relu'),\n",
    "tf.keras.layers.MaxPooling3D(pool_size=(2,2,4)),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dropout(0.1),\n",
    "tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "tf.keras.layers.Dropout(0.1),\n",
    "tf.keras.layers.Dense(40*40, activation = 'relu'),\n",
    "tf.keras.layers.Reshape((40,40)),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        moc, mocv = logs.get('MOC'), logs.get('MOC_val')\n",
    "        if(np.abs(float(moc)-float(mocv))>2*float(mocv)):\n",
    "            print(\"\\nSeparating behaviour!\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr = 0.001), \n",
    "              loss = PCCl, \n",
    "              metrics =[MOC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = home+\"/SyntheticData/syndat/\"\n",
    "\n",
    "X,Y = readdata(nframes,n=800,magn=4,repeat = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.9897 - MOC: 0.2426 - val_loss: 1.0075 - val_MOC: 0.1031\n",
      "Epoch 2/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.9773 - MOC: 0.2367 - val_loss: 1.0032 - val_MOC: 0.1076\n",
      "Epoch 3/50\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 0.9752 - MOC: 0.2467 - val_loss: 1.0032 - val_MOC: 0.1132\n",
      "Epoch 4/50\n",
      "3200/3200 [==============================] - 1s 385us/step - loss: 0.9675 - MOC: 0.2484 - val_loss: 0.9742 - val_MOC: 0.1125\n",
      "Epoch 5/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.9454 - MOC: 0.2452 - val_loss: 0.9553 - val_MOC: 0.1128\n",
      "Epoch 6/50\n",
      "3200/3200 [==============================] - 1s 396us/step - loss: 0.8798 - MOC: 0.2480 - val_loss: 0.8784 - val_MOC: 0.1820\n",
      "Epoch 7/50\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 0.8381 - MOC: 0.2764 - val_loss: 0.8567 - val_MOC: 0.1943\n",
      "Epoch 8/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.8035 - MOC: 0.2971 - val_loss: 0.8091 - val_MOC: 0.2436\n",
      "Epoch 9/50\n",
      "3200/3200 [==============================] - 1s 386us/step - loss: 0.7762 - MOC: 0.3148 - val_loss: 0.7978 - val_MOC: 0.2464\n",
      "Epoch 10/50\n",
      "3200/3200 [==============================] - 1s 386us/step - loss: 0.7531 - MOC: 0.3290 - val_loss: 0.7885 - val_MOC: 0.2546\n",
      "Epoch 11/50\n",
      "3200/3200 [==============================] - 1s 392us/step - loss: 0.7363 - MOC: 0.3394 - val_loss: 0.7850 - val_MOC: 0.2563\n",
      "Epoch 12/50\n",
      "3200/3200 [==============================] - 1s 397us/step - loss: 0.7103 - MOC: 0.3594 - val_loss: 0.7752 - val_MOC: 0.2620\n",
      "Epoch 13/50\n",
      "3200/3200 [==============================] - 1s 391us/step - loss: 0.6904 - MOC: 0.3719 - val_loss: 0.7682 - val_MOC: 0.2716\n",
      "Epoch 14/50\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 0.6696 - MOC: 0.3870 - val_loss: 0.7606 - val_MOC: 0.2760\n",
      "Epoch 15/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.6534 - MOC: 0.3995 - val_loss: 0.7442 - val_MOC: 0.2929\n",
      "Epoch 16/50\n",
      "3200/3200 [==============================] - 1s 386us/step - loss: 0.6349 - MOC: 0.4137 - val_loss: 0.7523 - val_MOC: 0.2818\n",
      "Epoch 17/50\n",
      "3200/3200 [==============================] - 1s 393us/step - loss: 0.6130 - MOC: 0.4301 - val_loss: 0.7558 - val_MOC: 0.2769\n",
      "Epoch 18/50\n",
      "3200/3200 [==============================] - 1s 388us/step - loss: 0.5998 - MOC: 0.4397 - val_loss: 0.7525 - val_MOC: 0.2873\n",
      "Epoch 19/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.5875 - MOC: 0.4503 - val_loss: 0.7499 - val_MOC: 0.2871\n",
      "Epoch 20/50\n",
      "3200/3200 [==============================] - 1s 392us/step - loss: 0.5700 - MOC: 0.4635 - val_loss: 0.7380 - val_MOC: 0.2956\n",
      "Epoch 21/50\n",
      "3200/3200 [==============================] - 1s 386us/step - loss: 0.5558 - MOC: 0.4742 - val_loss: 0.7493 - val_MOC: 0.2854\n",
      "Epoch 22/50\n",
      "3200/3200 [==============================] - 1s 392us/step - loss: 0.5473 - MOC: 0.4802 - val_loss: 0.7397 - val_MOC: 0.2925\n",
      "Epoch 23/50\n",
      "3200/3200 [==============================] - 1s 384us/step - loss: 0.5358 - MOC: 0.4894 - val_loss: 0.7369 - val_MOC: 0.2930\n",
      "Epoch 24/50\n",
      "3200/3200 [==============================] - 1s 388us/step - loss: 0.5228 - MOC: 0.5005 - val_loss: 0.7436 - val_MOC: 0.2882\n",
      "Epoch 25/50\n",
      "3200/3200 [==============================] - 1s 384us/step - loss: 0.5133 - MOC: 0.5074 - val_loss: 0.7356 - val_MOC: 0.2942\n",
      "Epoch 26/50\n",
      "3200/3200 [==============================] - 1s 384us/step - loss: 0.4973 - MOC: 0.5196 - val_loss: 0.7410 - val_MOC: 0.2878\n",
      "Epoch 27/50\n",
      "3200/3200 [==============================] - 1s 384us/step - loss: 0.4910 - MOC: 0.5248 - val_loss: 0.7449 - val_MOC: 0.2844\n",
      "Epoch 28/50\n",
      "3200/3200 [==============================] - 1s 388us/step - loss: 0.4864 - MOC: 0.5283 - val_loss: 0.7446 - val_MOC: 0.2842\n",
      "Epoch 29/50\n",
      "3200/3200 [==============================] - 1s 387us/step - loss: 0.4792 - MOC: 0.5340 - val_loss: 0.7461 - val_MOC: 0.2834\n",
      "Epoch 30/50\n",
      "3200/3200 [==============================] - 1s 399us/step - loss: 0.4664 - MOC: 0.5450 - val_loss: 0.7416 - val_MOC: 0.2873\n",
      "Epoch 31/50\n",
      "3200/3200 [==============================] - 1s 392us/step - loss: 0.4600 - MOC: 0.5497 - val_loss: 0.7490 - val_MOC: 0.2804\n",
      "Epoch 32/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.4607 - MOC: 0.5490 - val_loss: 0.7469 - val_MOC: 0.2851\n",
      "Epoch 33/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.4493 - MOC: 0.5593 - val_loss: 0.7485 - val_MOC: 0.2814\n",
      "Epoch 34/50\n",
      "3200/3200 [==============================] - 1s 400us/step - loss: 0.4451 - MOC: 0.5623 - val_loss: 0.7483 - val_MOC: 0.2808\n",
      "Epoch 35/50\n",
      "3200/3200 [==============================] - 1s 399us/step - loss: 0.4366 - MOC: 0.5698 - val_loss: 0.7431 - val_MOC: 0.2842\n",
      "Epoch 36/50\n",
      "3200/3200 [==============================] - 1s 388us/step - loss: 0.4343 - MOC: 0.5715 - val_loss: 0.7468 - val_MOC: 0.2824\n",
      "Epoch 37/50\n",
      "3200/3200 [==============================] - 1s 385us/step - loss: 0.4230 - MOC: 0.5810 - val_loss: 0.7469 - val_MOC: 0.2810\n",
      "Epoch 38/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.4223 - MOC: 0.5818 - val_loss: 0.7515 - val_MOC: 0.2792\n",
      "Epoch 39/50\n",
      "3200/3200 [==============================] - 1s 393us/step - loss: 0.4230 - MOC: 0.5812 - val_loss: 0.7424 - val_MOC: 0.2865\n",
      "Epoch 40/50\n",
      "3200/3200 [==============================] - 1s 385us/step - loss: 0.4121 - MOC: 0.5901 - val_loss: 0.7473 - val_MOC: 0.2814\n",
      "Epoch 41/50\n",
      "3200/3200 [==============================] - 1s 394us/step - loss: 0.4101 - MOC: 0.5919 - val_loss: 0.7460 - val_MOC: 0.2824\n",
      "Epoch 42/50\n",
      "3200/3200 [==============================] - 1s 391us/step - loss: 0.4044 - MOC: 0.5967 - val_loss: 0.7545 - val_MOC: 0.2743\n",
      "Epoch 43/50\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 0.4010 - MOC: 0.5992 - val_loss: 0.7475 - val_MOC: 0.2818\n",
      "Epoch 44/50\n",
      "3200/3200 [==============================] - 1s 393us/step - loss: 0.3990 - MOC: 0.6013 - val_loss: 0.7431 - val_MOC: 0.2860\n",
      "Epoch 45/50\n",
      "3200/3200 [==============================] - 1s 395us/step - loss: 0.3966 - MOC: 0.6035 - val_loss: 0.7427 - val_MOC: 0.2856\n",
      "Epoch 46/50\n",
      "3200/3200 [==============================] - 1s 400us/step - loss: 0.3893 - MOC: 0.6095 - val_loss: 0.7496 - val_MOC: 0.2796\n",
      "Epoch 47/50\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 0.3866 - MOC: 0.6119 - val_loss: 0.7475 - val_MOC: 0.2825\n",
      "Epoch 48/50\n",
      "3200/3200 [==============================] - 1s 390us/step - loss: 0.3846 - MOC: 0.6134 - val_loss: 0.7430 - val_MOC: 0.2848\n",
      "Epoch 49/50\n",
      "3200/3200 [==============================] - 1s 388us/step - loss: 0.3810 - MOC: 0.6167 - val_loss: 0.7515 - val_MOC: 0.2769\n",
      "Epoch 50/50\n",
      "3200/3200 [==============================] - 1s 387us/step - loss: 0.3772 - MOC: 0.6198 - val_loss: 0.7471 - val_MOC: 0.2819\n"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "ytr = np.abs(0.05*np.random.randn(Y.shape[0],Y.shape[1],Y.shape[2]))\n",
    "Y1 = Y +ytr\n",
    "history = model.fit(X,Y1, batch_size = 100, epochs = 50,\n",
    "                           validation_data = (Xdev,Ydev),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f12f1ba8a20>]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['MOC'],'C0',alpha=0.7)\n",
    "plt.plot(history.history['val_MOC'],'C0')\n",
    "plt.plot(history.history['loss'],'C1',alpha=0.7)\n",
    "plt.plot(history.history['val_loss'],'C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/mnt/data/synthetic/syndat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = readdata(nframes,n=900,magn=4,repeat = 4)\n",
    "historys = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.6691 - MOC: 0.3570 - val_loss: 0.6554 - val_MOC: 0.3756\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.5933 - MOC: 0.4327 - val_loss: 0.6411 - val_MOC: 0.3872\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.5595 - MOC: 0.4651 - val_loss: 0.6334 - val_MOC: 0.3963\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.5337 - MOC: 0.4896 - val_loss: 0.6298 - val_MOC: 0.3999\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.5155 - MOC: 0.5067 - val_loss: 0.6338 - val_MOC: 0.3947\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4972 - MOC: 0.5238 - val_loss: 0.6340 - val_MOC: 0.3941\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4824 - MOC: 0.5376 - val_loss: 0.6364 - val_MOC: 0.3931\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4682 - MOC: 0.5509 - val_loss: 0.6320 - val_MOC: 0.3959\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4574 - MOC: 0.5610 - val_loss: 0.6431 - val_MOC: 0.3845\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4456 - MOC: 0.5720 - val_loss: 0.6422 - val_MOC: 0.3854\n",
      "2\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.6425 - MOC: 0.3876 - val_loss: 0.6044 - val_MOC: 0.4252\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5877 - MOC: 0.4413 - val_loss: 0.5989 - val_MOC: 0.4302\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5540 - MOC: 0.4731 - val_loss: 0.6027 - val_MOC: 0.4267\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.5351 - MOC: 0.4905 - val_loss: 0.6019 - val_MOC: 0.4295\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5170 - MOC: 0.5077 - val_loss: 0.6048 - val_MOC: 0.4239\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4974 - MOC: 0.5257 - val_loss: 0.6089 - val_MOC: 0.4207\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4829 - MOC: 0.5391 - val_loss: 0.6156 - val_MOC: 0.4136\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4736 - MOC: 0.5475 - val_loss: 0.6198 - val_MOC: 0.4092\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4582 - MOC: 0.5620 - val_loss: 0.6217 - val_MOC: 0.4061\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4454 - MOC: 0.5738 - val_loss: 0.6231 - val_MOC: 0.4073\n",
      "3\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 422us/step - loss: 0.6254 - MOC: 0.4042 - val_loss: 0.5993 - val_MOC: 0.4343\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.5711 - MOC: 0.4574 - val_loss: 0.5897 - val_MOC: 0.4421\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5431 - MOC: 0.4838 - val_loss: 0.5956 - val_MOC: 0.4357\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5206 - MOC: 0.5049 - val_loss: 0.5971 - val_MOC: 0.4356\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5051 - MOC: 0.5192 - val_loss: 0.6032 - val_MOC: 0.4275\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4838 - MOC: 0.5391 - val_loss: 0.5987 - val_MOC: 0.4321\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4724 - MOC: 0.5493 - val_loss: 0.6123 - val_MOC: 0.4172\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4555 - MOC: 0.5653 - val_loss: 0.6164 - val_MOC: 0.4123\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4438 - MOC: 0.5759 - val_loss: 0.6190 - val_MOC: 0.4099\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4367 - MOC: 0.5824 - val_loss: 0.6239 - val_MOC: 0.4060\n",
      "4\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.6143 - MOC: 0.4153 - val_loss: 0.5926 - val_MOC: 0.4385\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.5620 - MOC: 0.4655 - val_loss: 0.5840 - val_MOC: 0.4475\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.5341 - MOC: 0.4923 - val_loss: 0.5920 - val_MOC: 0.4362\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 377us/step - loss: 0.5140 - MOC: 0.5108 - val_loss: 0.5885 - val_MOC: 0.4404\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4949 - MOC: 0.5286 - val_loss: 0.5907 - val_MOC: 0.4391\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4764 - MOC: 0.5457 - val_loss: 0.5952 - val_MOC: 0.4334\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4637 - MOC: 0.5574 - val_loss: 0.5962 - val_MOC: 0.4338\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4523 - MOC: 0.5681 - val_loss: 0.5983 - val_MOC: 0.4316\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 377us/step - loss: 0.4403 - MOC: 0.5791 - val_loss: 0.6031 - val_MOC: 0.4267\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4293 - MOC: 0.5895 - val_loss: 0.6138 - val_MOC: 0.4135\n",
      "5\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.6114 - MOC: 0.4183 - val_loss: 0.5926 - val_MOC: 0.4367\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5621 - MOC: 0.4660 - val_loss: 0.5769 - val_MOC: 0.4565\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5332 - MOC: 0.4935 - val_loss: 0.5897 - val_MOC: 0.4388\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5117 - MOC: 0.5133 - val_loss: 0.5788 - val_MOC: 0.4526\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4910 - MOC: 0.5326 - val_loss: 0.5834 - val_MOC: 0.4458\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4739 - MOC: 0.5482 - val_loss: 0.5836 - val_MOC: 0.4460\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4588 - MOC: 0.5623 - val_loss: 0.5957 - val_MOC: 0.4325\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4442 - MOC: 0.5758 - val_loss: 0.5987 - val_MOC: 0.4306\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4331 - MOC: 0.5860 - val_loss: 0.6024 - val_MOC: 0.4272\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4229 - MOC: 0.5955 - val_loss: 0.6107 - val_MOC: 0.4168\n",
      "6\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.6030 - MOC: 0.4256 - val_loss: 0.5823 - val_MOC: 0.4451\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5519 - MOC: 0.4751 - val_loss: 0.5639 - val_MOC: 0.4670\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5268 - MOC: 0.4989 - val_loss: 0.5687 - val_MOC: 0.4624\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5038 - MOC: 0.5203 - val_loss: 0.5713 - val_MOC: 0.4574\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.4818 - MOC: 0.5407 - val_loss: 0.5858 - val_MOC: 0.4439\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.4678 - MOC: 0.5538 - val_loss: 0.5808 - val_MOC: 0.4489\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4527 - MOC: 0.5678 - val_loss: 0.5844 - val_MOC: 0.4447\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4377 - MOC: 0.5816 - val_loss: 0.5970 - val_MOC: 0.4311\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4273 - MOC: 0.5911 - val_loss: 0.6019 - val_MOC: 0.4263\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4156 - MOC: 0.6021 - val_loss: 0.6006 - val_MOC: 0.4274\n",
      "7\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5939 - MOC: 0.4362 - val_loss: 0.5782 - val_MOC: 0.4526\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.5440 - MOC: 0.4842 - val_loss: 0.5757 - val_MOC: 0.4535\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5185 - MOC: 0.5085 - val_loss: 0.5694 - val_MOC: 0.4609\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 406us/step - loss: 0.4992 - MOC: 0.5265 - val_loss: 0.5671 - val_MOC: 0.4634\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4820 - MOC: 0.5424 - val_loss: 0.5696 - val_MOC: 0.4601\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4652 - MOC: 0.5579 - val_loss: 0.5812 - val_MOC: 0.4469\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4565 - MOC: 0.5658 - val_loss: 0.5841 - val_MOC: 0.4429\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4432 - MOC: 0.5781 - val_loss: 0.5882 - val_MOC: 0.4389\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4315 - MOC: 0.5890 - val_loss: 0.5830 - val_MOC: 0.4453\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4207 - MOC: 0.5988 - val_loss: 0.5925 - val_MOC: 0.4351\n",
      "8\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.5835 - MOC: 0.4445 - val_loss: 0.5664 - val_MOC: 0.4639\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5416 - MOC: 0.4855 - val_loss: 0.5626 - val_MOC: 0.4683\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5135 - MOC: 0.5122 - val_loss: 0.5570 - val_MOC: 0.4731\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4927 - MOC: 0.5315 - val_loss: 0.5648 - val_MOC: 0.4647\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4739 - MOC: 0.5489 - val_loss: 0.5669 - val_MOC: 0.4630\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4610 - MOC: 0.5609 - val_loss: 0.5793 - val_MOC: 0.4477\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.4497 - MOC: 0.5711 - val_loss: 0.5845 - val_MOC: 0.4446\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4371 - MOC: 0.5827 - val_loss: 0.5879 - val_MOC: 0.4407\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4236 - MOC: 0.5954 - val_loss: 0.5847 - val_MOC: 0.4434\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4127 - MOC: 0.6054 - val_loss: 0.5903 - val_MOC: 0.4376\n",
      "9\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5847 - MOC: 0.4441 - val_loss: 0.5763 - val_MOC: 0.4526\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5356 - MOC: 0.4916 - val_loss: 0.5671 - val_MOC: 0.4618\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5089 - MOC: 0.5166 - val_loss: 0.5603 - val_MOC: 0.4680\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4890 - MOC: 0.5351 - val_loss: 0.5664 - val_MOC: 0.4638\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4706 - MOC: 0.5521 - val_loss: 0.5641 - val_MOC: 0.4646\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4565 - MOC: 0.5652 - val_loss: 0.5695 - val_MOC: 0.4579\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4433 - MOC: 0.5773 - val_loss: 0.5736 - val_MOC: 0.4554\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4315 - MOC: 0.5883 - val_loss: 0.5779 - val_MOC: 0.4494\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4228 - MOC: 0.5963 - val_loss: 0.5808 - val_MOC: 0.4473\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4091 - MOC: 0.6090 - val_loss: 0.5937 - val_MOC: 0.4328\n",
      "10\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5914 - MOC: 0.4386 - val_loss: 0.5653 - val_MOC: 0.4638\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5430 - MOC: 0.4859 - val_loss: 0.5577 - val_MOC: 0.4720\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.5176 - MOC: 0.5097 - val_loss: 0.5572 - val_MOC: 0.4718\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4975 - MOC: 0.5283 - val_loss: 0.5474 - val_MOC: 0.4836\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4826 - MOC: 0.5421 - val_loss: 0.5601 - val_MOC: 0.4698\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4642 - MOC: 0.5591 - val_loss: 0.5582 - val_MOC: 0.4698\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4520 - MOC: 0.5702 - val_loss: 0.5617 - val_MOC: 0.4682\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4398 - MOC: 0.5815 - val_loss: 0.5630 - val_MOC: 0.4654\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4286 - MOC: 0.5917 - val_loss: 0.5714 - val_MOC: 0.4569\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4178 - MOC: 0.6017 - val_loss: 0.5703 - val_MOC: 0.4586\n",
      "11\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5806 - MOC: 0.4480 - val_loss: 0.5498 - val_MOC: 0.4798\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5316 - MOC: 0.4956 - val_loss: 0.5440 - val_MOC: 0.4861\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5051 - MOC: 0.5204 - val_loss: 0.5503 - val_MOC: 0.4779\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4859 - MOC: 0.5381 - val_loss: 0.5542 - val_MOC: 0.4733\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4697 - MOC: 0.5530 - val_loss: 0.5579 - val_MOC: 0.4707\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4537 - MOC: 0.5679 - val_loss: 0.5632 - val_MOC: 0.4651\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.4435 - MOC: 0.5772 - val_loss: 0.5680 - val_MOC: 0.4590\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4269 - MOC: 0.5927 - val_loss: 0.5699 - val_MOC: 0.4595\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4165 - MOC: 0.6021 - val_loss: 0.5754 - val_MOC: 0.4516\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4044 - MOC: 0.6134 - val_loss: 0.5764 - val_MOC: 0.4503\n",
      "12\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5821 - MOC: 0.4481 - val_loss: 0.5531 - val_MOC: 0.4777\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5376 - MOC: 0.4913 - val_loss: 0.5459 - val_MOC: 0.4843\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5112 - MOC: 0.5159 - val_loss: 0.5465 - val_MOC: 0.4831\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4928 - MOC: 0.5331 - val_loss: 0.5489 - val_MOC: 0.4790\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4767 - MOC: 0.5481 - val_loss: 0.5492 - val_MOC: 0.4793\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4612 - MOC: 0.5621 - val_loss: 0.5548 - val_MOC: 0.4722\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4474 - MOC: 0.5750 - val_loss: 0.5592 - val_MOC: 0.4675\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4379 - MOC: 0.5834 - val_loss: 0.5678 - val_MOC: 0.4588\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4242 - MOC: 0.5962 - val_loss: 0.5662 - val_MOC: 0.4616\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 376us/step - loss: 0.4168 - MOC: 0.6030 - val_loss: 0.5660 - val_MOC: 0.4611\n",
      "13\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 436us/step - loss: 0.5708 - MOC: 0.4577 - val_loss: 0.5573 - val_MOC: 0.4715\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5262 - MOC: 0.5006 - val_loss: 0.5479 - val_MOC: 0.4828\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.5013 - MOC: 0.5241 - val_loss: 0.5508 - val_MOC: 0.4799\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4816 - MOC: 0.5426 - val_loss: 0.5503 - val_MOC: 0.4792\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4657 - MOC: 0.5570 - val_loss: 0.5590 - val_MOC: 0.4693\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4491 - MOC: 0.5724 - val_loss: 0.5599 - val_MOC: 0.4685\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4404 - MOC: 0.5805 - val_loss: 0.5681 - val_MOC: 0.4599\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4263 - MOC: 0.5937 - val_loss: 0.5628 - val_MOC: 0.4654\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 421us/step - loss: 0.4142 - MOC: 0.6047 - val_loss: 0.5809 - val_MOC: 0.4449\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.4038 - MOC: 0.6144 - val_loss: 0.5769 - val_MOC: 0.4505\n",
      "14\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 408us/step - loss: 0.5681 - MOC: 0.4608 - val_loss: 0.5472 - val_MOC: 0.4833\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5239 - MOC: 0.5036 - val_loss: 0.5443 - val_MOC: 0.4848\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4990 - MOC: 0.5269 - val_loss: 0.5471 - val_MOC: 0.4814\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4795 - MOC: 0.5450 - val_loss: 0.5506 - val_MOC: 0.4775\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4616 - MOC: 0.5616 - val_loss: 0.5564 - val_MOC: 0.4726\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4467 - MOC: 0.5753 - val_loss: 0.5495 - val_MOC: 0.4794\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4341 - MOC: 0.5869 - val_loss: 0.5557 - val_MOC: 0.4723\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4237 - MOC: 0.5966 - val_loss: 0.5587 - val_MOC: 0.4696\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4093 - MOC: 0.6098 - val_loss: 0.5603 - val_MOC: 0.4672\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 425us/step - loss: 0.4004 - MOC: 0.6180 - val_loss: 0.5650 - val_MOC: 0.4631\n",
      "15\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5690 - MOC: 0.4597 - val_loss: 0.5519 - val_MOC: 0.4785\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5249 - MOC: 0.5025 - val_loss: 0.5501 - val_MOC: 0.4804\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4981 - MOC: 0.5277 - val_loss: 0.5490 - val_MOC: 0.4802\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4798 - MOC: 0.5445 - val_loss: 0.5530 - val_MOC: 0.4769\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4624 - MOC: 0.5606 - val_loss: 0.5541 - val_MOC: 0.4756\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4483 - MOC: 0.5737 - val_loss: 0.5713 - val_MOC: 0.4569\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4368 - MOC: 0.5841 - val_loss: 0.5657 - val_MOC: 0.4632\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4263 - MOC: 0.5939 - val_loss: 0.5699 - val_MOC: 0.4584\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4133 - MOC: 0.6059 - val_loss: 0.5735 - val_MOC: 0.4559\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4030 - MOC: 0.6155 - val_loss: 0.5793 - val_MOC: 0.4511\n",
      "16\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.5607 - MOC: 0.4683 - val_loss: 0.5570 - val_MOC: 0.4752\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.5194 - MOC: 0.5081 - val_loss: 0.5478 - val_MOC: 0.4836\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4947 - MOC: 0.5312 - val_loss: 0.5467 - val_MOC: 0.4833\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4753 - MOC: 0.5495 - val_loss: 0.5497 - val_MOC: 0.4783\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4597 - MOC: 0.5637 - val_loss: 0.5531 - val_MOC: 0.4768\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4476 - MOC: 0.5747 - val_loss: 0.5649 - val_MOC: 0.4626\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4320 - MOC: 0.5891 - val_loss: 0.5574 - val_MOC: 0.4713\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4216 - MOC: 0.5987 - val_loss: 0.5599 - val_MOC: 0.4673\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4102 - MOC: 0.6093 - val_loss: 0.5596 - val_MOC: 0.4692\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 417us/step - loss: 0.3993 - MOC: 0.6194 - val_loss: 0.5725 - val_MOC: 0.4561\n",
      "17\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.5692 - MOC: 0.4604 - val_loss: 0.5569 - val_MOC: 0.4736\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5270 - MOC: 0.5008 - val_loss: 0.5473 - val_MOC: 0.4819\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5001 - MOC: 0.5263 - val_loss: 0.5420 - val_MOC: 0.4877\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4823 - MOC: 0.5428 - val_loss: 0.5422 - val_MOC: 0.4882\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4664 - MOC: 0.5575 - val_loss: 0.5461 - val_MOC: 0.4814\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4511 - MOC: 0.5716 - val_loss: 0.5452 - val_MOC: 0.4836\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4388 - MOC: 0.5828 - val_loss: 0.5531 - val_MOC: 0.4758\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.4269 - MOC: 0.5939 - val_loss: 0.5596 - val_MOC: 0.4697\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4169 - MOC: 0.6030 - val_loss: 0.5587 - val_MOC: 0.4697\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4048 - MOC: 0.6142 - val_loss: 0.5702 - val_MOC: 0.4568\n",
      "18\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5635 - MOC: 0.4642 - val_loss: 0.5387 - val_MOC: 0.4924\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.5194 - MOC: 0.5070 - val_loss: 0.5388 - val_MOC: 0.4911\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4976 - MOC: 0.5274 - val_loss: 0.5406 - val_MOC: 0.4888\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4787 - MOC: 0.5446 - val_loss: 0.5422 - val_MOC: 0.4875\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4605 - MOC: 0.5619 - val_loss: 0.5508 - val_MOC: 0.4776\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4435 - MOC: 0.5775 - val_loss: 0.5520 - val_MOC: 0.4762\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4290 - MOC: 0.5909 - val_loss: 0.5540 - val_MOC: 0.4730\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4180 - MOC: 0.6010 - val_loss: 0.5577 - val_MOC: 0.4698\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4074 - MOC: 0.6108 - val_loss: 0.5655 - val_MOC: 0.4625\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3998 - MOC: 0.6179 - val_loss: 0.5726 - val_MOC: 0.4535\n",
      "19\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.5631 - MOC: 0.4657 - val_loss: 0.5412 - val_MOC: 0.4905\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5180 - MOC: 0.5094 - val_loss: 0.5402 - val_MOC: 0.4881\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4953 - MOC: 0.5305 - val_loss: 0.5300 - val_MOC: 0.4987\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4758 - MOC: 0.5484 - val_loss: 0.5329 - val_MOC: 0.4960\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4594 - MOC: 0.5637 - val_loss: 0.5411 - val_MOC: 0.4858\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 432us/step - loss: 0.4447 - MOC: 0.5771 - val_loss: 0.5383 - val_MOC: 0.4899\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 432us/step - loss: 0.4277 - MOC: 0.5929 - val_loss: 0.5407 - val_MOC: 0.4869\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4171 - MOC: 0.6027 - val_loss: 0.5460 - val_MOC: 0.4807\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4059 - MOC: 0.6130 - val_loss: 0.5503 - val_MOC: 0.4761\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3951 - MOC: 0.6229 - val_loss: 0.5495 - val_MOC: 0.4782\n",
      "20\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5570 - MOC: 0.4722 - val_loss: 0.5321 - val_MOC: 0.4974\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.5143 - MOC: 0.5136 - val_loss: 0.5289 - val_MOC: 0.5006\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4915 - MOC: 0.5346 - val_loss: 0.5326 - val_MOC: 0.4967\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4736 - MOC: 0.5512 - val_loss: 0.5343 - val_MOC: 0.4943\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4572 - MOC: 0.5665 - val_loss: 0.5344 - val_MOC: 0.4942\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4418 - MOC: 0.5807 - val_loss: 0.5438 - val_MOC: 0.4836\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 438us/step - loss: 0.4301 - MOC: 0.5912 - val_loss: 0.5475 - val_MOC: 0.4792\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4184 - MOC: 0.6021 - val_loss: 0.5477 - val_MOC: 0.4787\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4091 - MOC: 0.6106 - val_loss: 0.5501 - val_MOC: 0.4765\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4004 - MOC: 0.6186 - val_loss: 0.5551 - val_MOC: 0.4709\n",
      "21\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5597 - MOC: 0.4686 - val_loss: 0.5336 - val_MOC: 0.4954\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5190 - MOC: 0.5079 - val_loss: 0.5182 - val_MOC: 0.5122\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4981 - MOC: 0.5273 - val_loss: 0.5268 - val_MOC: 0.5025\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4720 - MOC: 0.5518 - val_loss: 0.5283 - val_MOC: 0.5001\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4582 - MOC: 0.5645 - val_loss: 0.5317 - val_MOC: 0.4953\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4450 - MOC: 0.5765 - val_loss: 0.5381 - val_MOC: 0.4900\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 426us/step - loss: 0.4302 - MOC: 0.5903 - val_loss: 0.5418 - val_MOC: 0.4858\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4194 - MOC: 0.6002 - val_loss: 0.5430 - val_MOC: 0.4847\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4085 - MOC: 0.6104 - val_loss: 0.5507 - val_MOC: 0.4763\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3979 - MOC: 0.6201 - val_loss: 0.5572 - val_MOC: 0.4704\n",
      "22\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.5523 - MOC: 0.4753 - val_loss: 0.5438 - val_MOC: 0.4846\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5082 - MOC: 0.5177 - val_loss: 0.5364 - val_MOC: 0.4922\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4866 - MOC: 0.5381 - val_loss: 0.5244 - val_MOC: 0.5055\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.4686 - MOC: 0.5549 - val_loss: 0.5394 - val_MOC: 0.4885\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4507 - MOC: 0.5714 - val_loss: 0.5336 - val_MOC: 0.4947\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4386 - MOC: 0.5826 - val_loss: 0.5471 - val_MOC: 0.4817\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4259 - MOC: 0.5945 - val_loss: 0.5422 - val_MOC: 0.4848\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4128 - MOC: 0.6067 - val_loss: 0.5475 - val_MOC: 0.4802\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4036 - MOC: 0.6149 - val_loss: 0.5673 - val_MOC: 0.4611\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3918 - MOC: 0.6259 - val_loss: 0.5582 - val_MOC: 0.4688\n",
      "23\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.5574 - MOC: 0.4715 - val_loss: 0.5310 - val_MOC: 0.4986\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5158 - MOC: 0.5117 - val_loss: 0.5251 - val_MOC: 0.5030\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4915 - MOC: 0.5344 - val_loss: 0.5265 - val_MOC: 0.5009\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.4740 - MOC: 0.5505 - val_loss: 0.5325 - val_MOC: 0.4957\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4585 - MOC: 0.5649 - val_loss: 0.5356 - val_MOC: 0.4916\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4460 - MOC: 0.5764 - val_loss: 0.5482 - val_MOC: 0.4804\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4352 - MOC: 0.5864 - val_loss: 0.5440 - val_MOC: 0.4842\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4249 - MOC: 0.5958 - val_loss: 0.5495 - val_MOC: 0.4789\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4114 - MOC: 0.6084 - val_loss: 0.5506 - val_MOC: 0.4764\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4007 - MOC: 0.6182 - val_loss: 0.5527 - val_MOC: 0.4756\n",
      "24\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5546 - MOC: 0.4736 - val_loss: 0.5369 - val_MOC: 0.4934\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.5128 - MOC: 0.5143 - val_loss: 0.5288 - val_MOC: 0.5007\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4915 - MOC: 0.5341 - val_loss: 0.5337 - val_MOC: 0.4947\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4744 - MOC: 0.5500 - val_loss: 0.5293 - val_MOC: 0.4992\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4579 - MOC: 0.5652 - val_loss: 0.5324 - val_MOC: 0.4966\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4437 - MOC: 0.5783 - val_loss: 0.5328 - val_MOC: 0.4942\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 434us/step - loss: 0.4308 - MOC: 0.5903 - val_loss: 0.5378 - val_MOC: 0.4900\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4191 - MOC: 0.6010 - val_loss: 0.5458 - val_MOC: 0.4815\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4077 - MOC: 0.6113 - val_loss: 0.5545 - val_MOC: 0.4719\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3966 - MOC: 0.6218 - val_loss: 0.5541 - val_MOC: 0.4733\n",
      "25\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5537 - MOC: 0.4748 - val_loss: 0.5279 - val_MOC: 0.5021\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.5145 - MOC: 0.5130 - val_loss: 0.5224 - val_MOC: 0.5063\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4913 - MOC: 0.5345 - val_loss: 0.5229 - val_MOC: 0.5050\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4763 - MOC: 0.5484 - val_loss: 0.5251 - val_MOC: 0.5030\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4581 - MOC: 0.5654 - val_loss: 0.5322 - val_MOC: 0.4957\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4450 - MOC: 0.5775 - val_loss: 0.5347 - val_MOC: 0.4929\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4348 - MOC: 0.5868 - val_loss: 0.5354 - val_MOC: 0.4918\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4215 - MOC: 0.5990 - val_loss: 0.5391 - val_MOC: 0.4878\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4107 - MOC: 0.6090 - val_loss: 0.5456 - val_MOC: 0.4807\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.4018 - MOC: 0.6172 - val_loss: 0.5442 - val_MOC: 0.4836\n",
      "26\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 407us/step - loss: 0.5508 - MOC: 0.4782 - val_loss: 0.5372 - val_MOC: 0.4923\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5099 - MOC: 0.5175 - val_loss: 0.5328 - val_MOC: 0.4960\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4879 - MOC: 0.5380 - val_loss: 0.5317 - val_MOC: 0.4977\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4713 - MOC: 0.5534 - val_loss: 0.5337 - val_MOC: 0.4948\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4543 - MOC: 0.5691 - val_loss: 0.5394 - val_MOC: 0.4886\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4391 - MOC: 0.5831 - val_loss: 0.5443 - val_MOC: 0.4838\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4268 - MOC: 0.5945 - val_loss: 0.5490 - val_MOC: 0.4791\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4160 - MOC: 0.6043 - val_loss: 0.5481 - val_MOC: 0.4804\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4047 - MOC: 0.6148 - val_loss: 0.5595 - val_MOC: 0.4671\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3970 - MOC: 0.6220 - val_loss: 0.5632 - val_MOC: 0.4643\n",
      "27\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.5510 - MOC: 0.4766 - val_loss: 0.5369 - val_MOC: 0.4927\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5088 - MOC: 0.5176 - val_loss: 0.5262 - val_MOC: 0.5043\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4881 - MOC: 0.5371 - val_loss: 0.5320 - val_MOC: 0.4975\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4676 - MOC: 0.5561 - val_loss: 0.5350 - val_MOC: 0.4930\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4534 - MOC: 0.5691 - val_loss: 0.5341 - val_MOC: 0.4935\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4381 - MOC: 0.5833 - val_loss: 0.5355 - val_MOC: 0.4925\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4273 - MOC: 0.5933 - val_loss: 0.5473 - val_MOC: 0.4804\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4147 - MOC: 0.6050 - val_loss: 0.5444 - val_MOC: 0.4827\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4026 - MOC: 0.6161 - val_loss: 0.5542 - val_MOC: 0.4726\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.3963 - MOC: 0.6219 - val_loss: 0.5629 - val_MOC: 0.4641\n",
      "28\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.5531 - MOC: 0.4749 - val_loss: 0.5381 - val_MOC: 0.4904\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5128 - MOC: 0.5138 - val_loss: 0.5349 - val_MOC: 0.4940\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4908 - MOC: 0.5346 - val_loss: 0.5302 - val_MOC: 0.4989\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4722 - MOC: 0.5518 - val_loss: 0.5351 - val_MOC: 0.4929\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4566 - MOC: 0.5664 - val_loss: 0.5402 - val_MOC: 0.4881\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4410 - MOC: 0.5806 - val_loss: 0.5423 - val_MOC: 0.4854\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4300 - MOC: 0.5909 - val_loss: 0.5430 - val_MOC: 0.4848\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4174 - MOC: 0.6024 - val_loss: 0.5471 - val_MOC: 0.4811\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4105 - MOC: 0.6088 - val_loss: 0.5631 - val_MOC: 0.4637\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4009 - MOC: 0.6176 - val_loss: 0.5581 - val_MOC: 0.4690\n",
      "29\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.5509 - MOC: 0.4773 - val_loss: 0.5334 - val_MOC: 0.4956\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5103 - MOC: 0.5163 - val_loss: 0.5306 - val_MOC: 0.4977\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4876 - MOC: 0.5377 - val_loss: 0.5255 - val_MOC: 0.5043\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4715 - MOC: 0.5526 - val_loss: 0.5362 - val_MOC: 0.4913\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4563 - MOC: 0.5666 - val_loss: 0.5320 - val_MOC: 0.4952\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4416 - MOC: 0.5802 - val_loss: 0.5271 - val_MOC: 0.5007\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4269 - MOC: 0.5938 - val_loss: 0.5327 - val_MOC: 0.4952\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4155 - MOC: 0.6043 - val_loss: 0.5432 - val_MOC: 0.4833\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4063 - MOC: 0.6128 - val_loss: 0.5470 - val_MOC: 0.4790\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3952 - MOC: 0.6230 - val_loss: 0.5491 - val_MOC: 0.4777\n",
      "30\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 2s 446us/step - loss: 0.5512 - MOC: 0.4776 - val_loss: 0.5305 - val_MOC: 0.4984\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5138 - MOC: 0.5138 - val_loss: 0.5227 - val_MOC: 0.5066\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4889 - MOC: 0.5371 - val_loss: 0.5283 - val_MOC: 0.5001\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4723 - MOC: 0.5524 - val_loss: 0.5370 - val_MOC: 0.4902\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4562 - MOC: 0.5673 - val_loss: 0.5304 - val_MOC: 0.4984\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4444 - MOC: 0.5782 - val_loss: 0.5350 - val_MOC: 0.4934\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4298 - MOC: 0.5915 - val_loss: 0.5382 - val_MOC: 0.4886\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4193 - MOC: 0.6012 - val_loss: 0.5477 - val_MOC: 0.4798\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4087 - MOC: 0.6109 - val_loss: 0.5478 - val_MOC: 0.4799\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.3998 - MOC: 0.6191 - val_loss: 0.5527 - val_MOC: 0.4751\n",
      "31\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5462 - MOC: 0.4818 - val_loss: 0.5355 - val_MOC: 0.4924\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5089 - MOC: 0.5182 - val_loss: 0.5172 - val_MOC: 0.5107\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4865 - MOC: 0.5393 - val_loss: 0.5181 - val_MOC: 0.5103\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4687 - MOC: 0.5557 - val_loss: 0.5183 - val_MOC: 0.5091\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4539 - MOC: 0.5693 - val_loss: 0.5204 - val_MOC: 0.5067\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4409 - MOC: 0.5815 - val_loss: 0.5232 - val_MOC: 0.5038\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4249 - MOC: 0.5961 - val_loss: 0.5304 - val_MOC: 0.4954\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.4158 - MOC: 0.6044 - val_loss: 0.5327 - val_MOC: 0.4933\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4062 - MOC: 0.6134 - val_loss: 0.5316 - val_MOC: 0.4944\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3949 - MOC: 0.6237 - val_loss: 0.5385 - val_MOC: 0.4876\n",
      "32\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5469 - MOC: 0.4811 - val_loss: 0.5198 - val_MOC: 0.5075\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.5085 - MOC: 0.5183 - val_loss: 0.5183 - val_MOC: 0.5104\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4870 - MOC: 0.5384 - val_loss: 0.5249 - val_MOC: 0.5025\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4706 - MOC: 0.5536 - val_loss: 0.5184 - val_MOC: 0.5096\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4558 - MOC: 0.5671 - val_loss: 0.5295 - val_MOC: 0.4966\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4425 - MOC: 0.5795 - val_loss: 0.5198 - val_MOC: 0.5071\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4318 - MOC: 0.5893 - val_loss: 0.5334 - val_MOC: 0.4934\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4222 - MOC: 0.5982 - val_loss: 0.5316 - val_MOC: 0.4949\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 453us/step - loss: 0.4098 - MOC: 0.6096 - val_loss: 0.5389 - val_MOC: 0.4875\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4024 - MOC: 0.6165 - val_loss: 0.5395 - val_MOC: 0.4869\n",
      "33\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 458us/step - loss: 0.5434 - MOC: 0.4847 - val_loss: 0.5209 - val_MOC: 0.5071\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5038 - MOC: 0.5228 - val_loss: 0.5138 - val_MOC: 0.5147\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4827 - MOC: 0.5428 - val_loss: 0.5170 - val_MOC: 0.5102\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4681 - MOC: 0.5562 - val_loss: 0.5256 - val_MOC: 0.5010\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4513 - MOC: 0.5718 - val_loss: 0.5237 - val_MOC: 0.5034\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4417 - MOC: 0.5805 - val_loss: 0.5234 - val_MOC: 0.5045\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4289 - MOC: 0.5923 - val_loss: 0.5312 - val_MOC: 0.4952\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4171 - MOC: 0.6032 - val_loss: 0.5295 - val_MOC: 0.4975\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4055 - MOC: 0.6139 - val_loss: 0.5296 - val_MOC: 0.4979\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4000 - MOC: 0.6190 - val_loss: 0.5420 - val_MOC: 0.4849\n",
      "34\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 463us/step - loss: 0.5419 - MOC: 0.4855 - val_loss: 0.5331 - val_MOC: 0.4947\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5053 - MOC: 0.5209 - val_loss: 0.5159 - val_MOC: 0.5128\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4833 - MOC: 0.5414 - val_loss: 0.5202 - val_MOC: 0.5082\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4661 - MOC: 0.5575 - val_loss: 0.5158 - val_MOC: 0.5112\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4487 - MOC: 0.5737 - val_loss: 0.5201 - val_MOC: 0.5070\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4366 - MOC: 0.5848 - val_loss: 0.5220 - val_MOC: 0.5053\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4238 - MOC: 0.5966 - val_loss: 0.5236 - val_MOC: 0.5039\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4131 - MOC: 0.6065 - val_loss: 0.5308 - val_MOC: 0.4962\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4057 - MOC: 0.6132 - val_loss: 0.5372 - val_MOC: 0.4883\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3941 - MOC: 0.6241 - val_loss: 0.5441 - val_MOC: 0.4814\n",
      "35\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.5423 - MOC: 0.4851 - val_loss: 0.5265 - val_MOC: 0.5004\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5029 - MOC: 0.5231 - val_loss: 0.5145 - val_MOC: 0.5133\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4827 - MOC: 0.5421 - val_loss: 0.5144 - val_MOC: 0.5132\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4635 - MOC: 0.5598 - val_loss: 0.5180 - val_MOC: 0.5094\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4482 - MOC: 0.5741 - val_loss: 0.5204 - val_MOC: 0.5062\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4356 - MOC: 0.5857 - val_loss: 0.5276 - val_MOC: 0.4985\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4229 - MOC: 0.5974 - val_loss: 0.5273 - val_MOC: 0.4991\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4139 - MOC: 0.6056 - val_loss: 0.5248 - val_MOC: 0.5017\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4024 - MOC: 0.6165 - val_loss: 0.5397 - val_MOC: 0.4858\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.3908 - MOC: 0.6269 - val_loss: 0.5393 - val_MOC: 0.4879\n",
      "36\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 407us/step - loss: 0.5382 - MOC: 0.4889 - val_loss: 0.5149 - val_MOC: 0.5128\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4996 - MOC: 0.5264 - val_loss: 0.5214 - val_MOC: 0.5051\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4761 - MOC: 0.5482 - val_loss: 0.5183 - val_MOC: 0.5083\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4614 - MOC: 0.5619 - val_loss: 0.5122 - val_MOC: 0.5148\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4450 - MOC: 0.5772 - val_loss: 0.5139 - val_MOC: 0.5132\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.4325 - MOC: 0.5887 - val_loss: 0.5259 - val_MOC: 0.5001\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.4204 - MOC: 0.5999 - val_loss: 0.5288 - val_MOC: 0.4975\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4112 - MOC: 0.6084 - val_loss: 0.5234 - val_MOC: 0.5033\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3978 - MOC: 0.6208 - val_loss: 0.5236 - val_MOC: 0.5032\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3932 - MOC: 0.6250 - val_loss: 0.5329 - val_MOC: 0.4931\n",
      "37\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5395 - MOC: 0.4881 - val_loss: 0.5244 - val_MOC: 0.5030\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.5067 - MOC: 0.5201 - val_loss: 0.5242 - val_MOC: 0.5026\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4811 - MOC: 0.5439 - val_loss: 0.5091 - val_MOC: 0.5185\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4642 - MOC: 0.5595 - val_loss: 0.5226 - val_MOC: 0.5044\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4492 - MOC: 0.5735 - val_loss: 0.5198 - val_MOC: 0.5075\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4378 - MOC: 0.5840 - val_loss: 0.5240 - val_MOC: 0.5028\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.4244 - MOC: 0.5963 - val_loss: 0.5312 - val_MOC: 0.4953\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4146 - MOC: 0.6053 - val_loss: 0.5347 - val_MOC: 0.4911\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4051 - MOC: 0.6139 - val_loss: 0.5387 - val_MOC: 0.4872\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.3929 - MOC: 0.6254 - val_loss: 0.5368 - val_MOC: 0.4902\n",
      "38\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.5435 - MOC: 0.4853 - val_loss: 0.5196 - val_MOC: 0.5086\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.5061 - MOC: 0.5214 - val_loss: 0.5157 - val_MOC: 0.5113\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4856 - MOC: 0.5406 - val_loss: 0.5111 - val_MOC: 0.5167\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4677 - MOC: 0.5571 - val_loss: 0.5178 - val_MOC: 0.5099\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4557 - MOC: 0.5681 - val_loss: 0.5247 - val_MOC: 0.5028\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4422 - MOC: 0.5806 - val_loss: 0.5179 - val_MOC: 0.5096\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.4291 - MOC: 0.5928 - val_loss: 0.5194 - val_MOC: 0.5073\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4187 - MOC: 0.6023 - val_loss: 0.5217 - val_MOC: 0.5055\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4057 - MOC: 0.6143 - val_loss: 0.5246 - val_MOC: 0.5027\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.3956 - MOC: 0.6235 - val_loss: 0.5315 - val_MOC: 0.4947\n",
      "39\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5414 - MOC: 0.4864 - val_loss: 0.5147 - val_MOC: 0.5145\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.5019 - MOC: 0.5243 - val_loss: 0.5177 - val_MOC: 0.5096\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4817 - MOC: 0.5432 - val_loss: 0.5206 - val_MOC: 0.5061\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4652 - MOC: 0.5584 - val_loss: 0.5197 - val_MOC: 0.5073\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.4469 - MOC: 0.5756 - val_loss: 0.5251 - val_MOC: 0.5008\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.4342 - MOC: 0.5870 - val_loss: 0.5254 - val_MOC: 0.5019\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4247 - MOC: 0.5959 - val_loss: 0.5282 - val_MOC: 0.4981\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4111 - MOC: 0.6085 - val_loss: 0.5403 - val_MOC: 0.4857\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4015 - MOC: 0.6174 - val_loss: 0.5397 - val_MOC: 0.4873\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3928 - MOC: 0.6254 - val_loss: 0.5361 - val_MOC: 0.4915\n",
      "40\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.5405 - MOC: 0.4878 - val_loss: 0.5269 - val_MOC: 0.5012\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.5053 - MOC: 0.5218 - val_loss: 0.5120 - val_MOC: 0.5160\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4820 - MOC: 0.5437 - val_loss: 0.5176 - val_MOC: 0.5103\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 408us/step - loss: 0.4681 - MOC: 0.5566 - val_loss: 0.5109 - val_MOC: 0.5167\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 419us/step - loss: 0.4521 - MOC: 0.5714 - val_loss: 0.5152 - val_MOC: 0.5120\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4392 - MOC: 0.5832 - val_loss: 0.5182 - val_MOC: 0.5101\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4285 - MOC: 0.5931 - val_loss: 0.5182 - val_MOC: 0.5075\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4167 - MOC: 0.6040 - val_loss: 0.5223 - val_MOC: 0.5039\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4086 - MOC: 0.6113 - val_loss: 0.5212 - val_MOC: 0.5055\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3997 - MOC: 0.6196 - val_loss: 0.5246 - val_MOC: 0.5015\n",
      "41\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5306 - MOC: 0.4966 - val_loss: 0.5170 - val_MOC: 0.5109\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4968 - MOC: 0.5296 - val_loss: 0.5092 - val_MOC: 0.5184\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4726 - MOC: 0.5522 - val_loss: 0.5090 - val_MOC: 0.5190\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4573 - MOC: 0.5662 - val_loss: 0.5155 - val_MOC: 0.5121\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 424us/step - loss: 0.4407 - MOC: 0.5817 - val_loss: 0.5108 - val_MOC: 0.5163\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4311 - MOC: 0.5905 - val_loss: 0.5127 - val_MOC: 0.5148\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4188 - MOC: 0.6019 - val_loss: 0.5319 - val_MOC: 0.4941\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4096 - MOC: 0.6103 - val_loss: 0.5242 - val_MOC: 0.5022\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3973 - MOC: 0.6217 - val_loss: 0.5272 - val_MOC: 0.4993\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3887 - MOC: 0.6295 - val_loss: 0.5300 - val_MOC: 0.4959\n",
      "42\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 436us/step - loss: 0.5338 - MOC: 0.4944 - val_loss: 0.5092 - val_MOC: 0.5204\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4948 - MOC: 0.5320 - val_loss: 0.5019 - val_MOC: 0.5261\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4745 - MOC: 0.5511 - val_loss: 0.5029 - val_MOC: 0.5252\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4571 - MOC: 0.5671 - val_loss: 0.5044 - val_MOC: 0.5232\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4425 - MOC: 0.5807 - val_loss: 0.5065 - val_MOC: 0.5200\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4318 - MOC: 0.5904 - val_loss: 0.5068 - val_MOC: 0.5209\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4195 - MOC: 0.6017 - val_loss: 0.5063 - val_MOC: 0.5207\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4072 - MOC: 0.6132 - val_loss: 0.5114 - val_MOC: 0.5152\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3971 - MOC: 0.6224 - val_loss: 0.5138 - val_MOC: 0.5128\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3886 - MOC: 0.6301 - val_loss: 0.5162 - val_MOC: 0.5113\n",
      "43\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 430us/step - loss: 0.5406 - MOC: 0.4882 - val_loss: 0.5092 - val_MOC: 0.5196\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4997 - MOC: 0.5273 - val_loss: 0.4985 - val_MOC: 0.5288\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4819 - MOC: 0.5440 - val_loss: 0.4958 - val_MOC: 0.5317\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4667 - MOC: 0.5582 - val_loss: 0.4970 - val_MOC: 0.5298\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4512 - MOC: 0.5723 - val_loss: 0.4965 - val_MOC: 0.5309\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4385 - MOC: 0.5841 - val_loss: 0.5014 - val_MOC: 0.5253\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4262 - MOC: 0.5954 - val_loss: 0.5044 - val_MOC: 0.5231\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4178 - MOC: 0.6032 - val_loss: 0.5042 - val_MOC: 0.5231\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4052 - MOC: 0.6149 - val_loss: 0.5150 - val_MOC: 0.5104\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3991 - MOC: 0.6202 - val_loss: 0.5092 - val_MOC: 0.5172\n",
      "44\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 456us/step - loss: 0.5342 - MOC: 0.4940 - val_loss: 0.5034 - val_MOC: 0.5239\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.5003 - MOC: 0.5267 - val_loss: 0.5029 - val_MOC: 0.5246\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4783 - MOC: 0.5472 - val_loss: 0.5012 - val_MOC: 0.5252\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4630 - MOC: 0.5614 - val_loss: 0.5033 - val_MOC: 0.5227\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4480 - MOC: 0.5752 - val_loss: 0.5064 - val_MOC: 0.5203\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4359 - MOC: 0.5863 - val_loss: 0.5037 - val_MOC: 0.5244\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4239 - MOC: 0.5974 - val_loss: 0.5104 - val_MOC: 0.5152\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4129 - MOC: 0.6075 - val_loss: 0.5088 - val_MOC: 0.5178\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4022 - MOC: 0.6173 - val_loss: 0.5169 - val_MOC: 0.5096\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3942 - MOC: 0.6247 - val_loss: 0.5256 - val_MOC: 0.5005\n",
      "45\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 406us/step - loss: 0.5379 - MOC: 0.4889 - val_loss: 0.5013 - val_MOC: 0.5274\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.5017 - MOC: 0.5239 - val_loss: 0.5032 - val_MOC: 0.5239\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4838 - MOC: 0.5407 - val_loss: 0.5018 - val_MOC: 0.5251\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4648 - MOC: 0.5583 - val_loss: 0.4981 - val_MOC: 0.5288\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 449us/step - loss: 0.4520 - MOC: 0.5701 - val_loss: 0.5014 - val_MOC: 0.5262\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4399 - MOC: 0.5814 - val_loss: 0.5073 - val_MOC: 0.5194\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4284 - MOC: 0.5919 - val_loss: 0.5140 - val_MOC: 0.5109\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4134 - MOC: 0.6059 - val_loss: 0.5107 - val_MOC: 0.5150\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4049 - MOC: 0.6138 - val_loss: 0.5114 - val_MOC: 0.5145\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3997 - MOC: 0.6186 - val_loss: 0.5268 - val_MOC: 0.4987\n",
      "46\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 453us/step - loss: 0.5331 - MOC: 0.4945 - val_loss: 0.5037 - val_MOC: 0.5251\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4981 - MOC: 0.5284 - val_loss: 0.5010 - val_MOC: 0.5269\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4779 - MOC: 0.5474 - val_loss: 0.4998 - val_MOC: 0.5275\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4625 - MOC: 0.5615 - val_loss: 0.5027 - val_MOC: 0.5254\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4470 - MOC: 0.5759 - val_loss: 0.5111 - val_MOC: 0.5152\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4342 - MOC: 0.5877 - val_loss: 0.5070 - val_MOC: 0.5198\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4247 - MOC: 0.5966 - val_loss: 0.5135 - val_MOC: 0.5122\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4151 - MOC: 0.6053 - val_loss: 0.5103 - val_MOC: 0.5163\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4044 - MOC: 0.6151 - val_loss: 0.5165 - val_MOC: 0.5095\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3969 - MOC: 0.6221 - val_loss: 0.5167 - val_MOC: 0.5095\n",
      "47\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 414us/step - loss: 0.5303 - MOC: 0.4970 - val_loss: 0.5096 - val_MOC: 0.5193\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4927 - MOC: 0.5332 - val_loss: 0.5082 - val_MOC: 0.5191\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4713 - MOC: 0.5532 - val_loss: 0.5139 - val_MOC: 0.5127\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4557 - MOC: 0.5677 - val_loss: 0.5081 - val_MOC: 0.5194\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4406 - MOC: 0.5817 - val_loss: 0.5129 - val_MOC: 0.5145\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4269 - MOC: 0.5945 - val_loss: 0.5119 - val_MOC: 0.5155\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4195 - MOC: 0.6012 - val_loss: 0.5162 - val_MOC: 0.5105\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4054 - MOC: 0.6143 - val_loss: 0.5156 - val_MOC: 0.5114\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3979 - MOC: 0.6211 - val_loss: 0.5267 - val_MOC: 0.4997\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3887 - MOC: 0.6297 - val_loss: 0.5256 - val_MOC: 0.5009\n",
      "48\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 417us/step - loss: 0.5328 - MOC: 0.4949 - val_loss: 0.5121 - val_MOC: 0.5159\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4975 - MOC: 0.5289 - val_loss: 0.5019 - val_MOC: 0.5262\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4755 - MOC: 0.5497 - val_loss: 0.5062 - val_MOC: 0.5210\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4571 - MOC: 0.5665 - val_loss: 0.5078 - val_MOC: 0.5201\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4426 - MOC: 0.5799 - val_loss: 0.5177 - val_MOC: 0.5095\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4317 - MOC: 0.5901 - val_loss: 0.5189 - val_MOC: 0.5084\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4207 - MOC: 0.6000 - val_loss: 0.5189 - val_MOC: 0.5083\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4076 - MOC: 0.6122 - val_loss: 0.5263 - val_MOC: 0.4997\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4001 - MOC: 0.6192 - val_loss: 0.5254 - val_MOC: 0.5010\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 420us/step - loss: 0.3903 - MOC: 0.6282 - val_loss: 0.5310 - val_MOC: 0.4951\n",
      "49\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5367 - MOC: 0.4911 - val_loss: 0.5136 - val_MOC: 0.5143\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5007 - MOC: 0.5259 - val_loss: 0.5045 - val_MOC: 0.5242\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4803 - MOC: 0.5450 - val_loss: 0.5036 - val_MOC: 0.5251\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4644 - MOC: 0.5598 - val_loss: 0.5020 - val_MOC: 0.5261\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4495 - MOC: 0.5735 - val_loss: 0.5080 - val_MOC: 0.5192\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4383 - MOC: 0.5838 - val_loss: 0.5147 - val_MOC: 0.5116\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4256 - MOC: 0.5954 - val_loss: 0.5168 - val_MOC: 0.5099\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4139 - MOC: 0.6062 - val_loss: 0.5154 - val_MOC: 0.5107\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4033 - MOC: 0.6158 - val_loss: 0.5195 - val_MOC: 0.5068\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3969 - MOC: 0.6219 - val_loss: 0.5256 - val_MOC: 0.5008\n",
      "50\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5398 - MOC: 0.4881 - val_loss: 0.5110 - val_MOC: 0.5164\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.5035 - MOC: 0.5232 - val_loss: 0.5009 - val_MOC: 0.5273\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4848 - MOC: 0.5406 - val_loss: 0.5014 - val_MOC: 0.5267\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4691 - MOC: 0.5552 - val_loss: 0.5023 - val_MOC: 0.5262\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 426us/step - loss: 0.4541 - MOC: 0.5690 - val_loss: 0.5025 - val_MOC: 0.5253\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.4434 - MOC: 0.5789 - val_loss: 0.5135 - val_MOC: 0.5129\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4313 - MOC: 0.5899 - val_loss: 0.5089 - val_MOC: 0.5191\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4204 - MOC: 0.6001 - val_loss: 0.5106 - val_MOC: 0.5161\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4102 - MOC: 0.6095 - val_loss: 0.5178 - val_MOC: 0.5091\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4012 - MOC: 0.6178 - val_loss: 0.5180 - val_MOC: 0.5086\n",
      "51\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5291 - MOC: 0.4973 - val_loss: 0.5049 - val_MOC: 0.5229\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4928 - MOC: 0.5323 - val_loss: 0.5054 - val_MOC: 0.5213\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4743 - MOC: 0.5497 - val_loss: 0.5058 - val_MOC: 0.5204\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4582 - MOC: 0.5647 - val_loss: 0.4980 - val_MOC: 0.5286\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4439 - MOC: 0.5779 - val_loss: 0.4984 - val_MOC: 0.5277\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.4307 - MOC: 0.5900 - val_loss: 0.4948 - val_MOC: 0.5324\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4195 - MOC: 0.6006 - val_loss: 0.5102 - val_MOC: 0.5156\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4095 - MOC: 0.6098 - val_loss: 0.5093 - val_MOC: 0.5170\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.3978 - MOC: 0.6207 - val_loss: 0.5145 - val_MOC: 0.5114\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3895 - MOC: 0.6282 - val_loss: 0.5233 - val_MOC: 0.5015\n",
      "52\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5338 - MOC: 0.4938 - val_loss: 0.5061 - val_MOC: 0.5215\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.5003 - MOC: 0.5263 - val_loss: 0.5039 - val_MOC: 0.5233\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4794 - MOC: 0.5459 - val_loss: 0.5090 - val_MOC: 0.5182\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 377us/step - loss: 0.4630 - MOC: 0.5611 - val_loss: 0.5056 - val_MOC: 0.5219\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4501 - MOC: 0.5731 - val_loss: 0.5090 - val_MOC: 0.5176\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4371 - MOC: 0.5851 - val_loss: 0.5167 - val_MOC: 0.5102\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4278 - MOC: 0.5937 - val_loss: 0.5185 - val_MOC: 0.5082\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4143 - MOC: 0.6061 - val_loss: 0.5270 - val_MOC: 0.4986\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 423us/step - loss: 0.4070 - MOC: 0.6127 - val_loss: 0.5230 - val_MOC: 0.5040\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.3943 - MOC: 0.6246 - val_loss: 0.5277 - val_MOC: 0.4986\n",
      "53\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5281 - MOC: 0.4991 - val_loss: 0.5073 - val_MOC: 0.5207\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4964 - MOC: 0.5297 - val_loss: 0.5057 - val_MOC: 0.5209\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4775 - MOC: 0.5472 - val_loss: 0.5015 - val_MOC: 0.5258\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4636 - MOC: 0.5602 - val_loss: 0.5002 - val_MOC: 0.5264\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.4519 - MOC: 0.5710 - val_loss: 0.4985 - val_MOC: 0.5286\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4370 - MOC: 0.5849 - val_loss: 0.5018 - val_MOC: 0.5245\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4250 - MOC: 0.5958 - val_loss: 0.5018 - val_MOC: 0.5248\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.4171 - MOC: 0.6033 - val_loss: 0.5090 - val_MOC: 0.5169\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4075 - MOC: 0.6120 - val_loss: 0.5116 - val_MOC: 0.5142\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3978 - MOC: 0.6210 - val_loss: 0.5221 - val_MOC: 0.5036\n",
      "54\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5319 - MOC: 0.4955 - val_loss: 0.4971 - val_MOC: 0.5322\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5002 - MOC: 0.5263 - val_loss: 0.5026 - val_MOC: 0.5246\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4781 - MOC: 0.5470 - val_loss: 0.4970 - val_MOC: 0.5305\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 436us/step - loss: 0.4619 - MOC: 0.5619 - val_loss: 0.4946 - val_MOC: 0.5321\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4468 - MOC: 0.5760 - val_loss: 0.4984 - val_MOC: 0.5285\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4360 - MOC: 0.5861 - val_loss: 0.5010 - val_MOC: 0.5246\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4246 - MOC: 0.5964 - val_loss: 0.4957 - val_MOC: 0.5307\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4144 - MOC: 0.6059 - val_loss: 0.5032 - val_MOC: 0.5233\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4083 - MOC: 0.6114 - val_loss: 0.5089 - val_MOC: 0.5164\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3964 - MOC: 0.6226 - val_loss: 0.5119 - val_MOC: 0.5138\n",
      "55\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 445us/step - loss: 0.5303 - MOC: 0.4970 - val_loss: 0.4973 - val_MOC: 0.5304\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4963 - MOC: 0.5301 - val_loss: 0.4978 - val_MOC: 0.5284\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4760 - MOC: 0.5488 - val_loss: 0.4938 - val_MOC: 0.5325\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4616 - MOC: 0.5623 - val_loss: 0.4903 - val_MOC: 0.5370\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4490 - MOC: 0.5740 - val_loss: 0.4945 - val_MOC: 0.5322\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4338 - MOC: 0.5882 - val_loss: 0.5076 - val_MOC: 0.5178\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4245 - MOC: 0.5963 - val_loss: 0.5005 - val_MOC: 0.5262\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4136 - MOC: 0.6067 - val_loss: 0.5013 - val_MOC: 0.5260\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4037 - MOC: 0.6158 - val_loss: 0.5122 - val_MOC: 0.5134\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3947 - MOC: 0.6242 - val_loss: 0.5114 - val_MOC: 0.5139\n",
      "56\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 434us/step - loss: 0.5264 - MOC: 0.5002 - val_loss: 0.5121 - val_MOC: 0.5147\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4957 - MOC: 0.5298 - val_loss: 0.4998 - val_MOC: 0.5283\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4729 - MOC: 0.5513 - val_loss: 0.4999 - val_MOC: 0.5274\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4594 - MOC: 0.5638 - val_loss: 0.4992 - val_MOC: 0.5289\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4459 - MOC: 0.5763 - val_loss: 0.5104 - val_MOC: 0.5161\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4332 - MOC: 0.5881 - val_loss: 0.5086 - val_MOC: 0.5186\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4245 - MOC: 0.5960 - val_loss: 0.5185 - val_MOC: 0.5081\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4151 - MOC: 0.6048 - val_loss: 0.5186 - val_MOC: 0.5079\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4016 - MOC: 0.6172 - val_loss: 0.5193 - val_MOC: 0.5072\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.3922 - MOC: 0.6260 - val_loss: 0.5301 - val_MOC: 0.4953\n",
      "57\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 442us/step - loss: 0.5301 - MOC: 0.4971 - val_loss: 0.5123 - val_MOC: 0.5159\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4955 - MOC: 0.5307 - val_loss: 0.4987 - val_MOC: 0.5295\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4753 - MOC: 0.5497 - val_loss: 0.5027 - val_MOC: 0.5241\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4629 - MOC: 0.5611 - val_loss: 0.4997 - val_MOC: 0.5272\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4477 - MOC: 0.5754 - val_loss: 0.5008 - val_MOC: 0.5262\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4343 - MOC: 0.5876 - val_loss: 0.4963 - val_MOC: 0.5308\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4251 - MOC: 0.5962 - val_loss: 0.5048 - val_MOC: 0.5215\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.4145 - MOC: 0.6059 - val_loss: 0.5061 - val_MOC: 0.5203\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4055 - MOC: 0.6142 - val_loss: 0.5156 - val_MOC: 0.5095\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3975 - MOC: 0.6216 - val_loss: 0.5163 - val_MOC: 0.5093\n",
      "58\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 424us/step - loss: 0.5269 - MOC: 0.5000 - val_loss: 0.4974 - val_MOC: 0.5298\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4930 - MOC: 0.5329 - val_loss: 0.4925 - val_MOC: 0.5336\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4744 - MOC: 0.5503 - val_loss: 0.4893 - val_MOC: 0.5375\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4575 - MOC: 0.5659 - val_loss: 0.4932 - val_MOC: 0.5329\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4427 - MOC: 0.5797 - val_loss: 0.4945 - val_MOC: 0.5306\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4324 - MOC: 0.5890 - val_loss: 0.4944 - val_MOC: 0.5313\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4194 - MOC: 0.6013 - val_loss: 0.4957 - val_MOC: 0.5303\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4086 - MOC: 0.6112 - val_loss: 0.4952 - val_MOC: 0.5304\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4010 - MOC: 0.6181 - val_loss: 0.5008 - val_MOC: 0.5252\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.3920 - MOC: 0.6265 - val_loss: 0.5084 - val_MOC: 0.5168\n",
      "59\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.5324 - MOC: 0.4947 - val_loss: 0.4973 - val_MOC: 0.5305\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4984 - MOC: 0.5275 - val_loss: 0.4886 - val_MOC: 0.5395\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 2s 450us/step - loss: 0.4763 - MOC: 0.5482 - val_loss: 0.4913 - val_MOC: 0.5354\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.4623 - MOC: 0.5611 - val_loss: 0.4948 - val_MOC: 0.5314\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4491 - MOC: 0.5732 - val_loss: 0.4935 - val_MOC: 0.5331\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4368 - MOC: 0.5846 - val_loss: 0.5033 - val_MOC: 0.5221\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4233 - MOC: 0.5971 - val_loss: 0.5036 - val_MOC: 0.5220\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4132 - MOC: 0.6065 - val_loss: 0.5028 - val_MOC: 0.5228\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4061 - MOC: 0.6130 - val_loss: 0.5005 - val_MOC: 0.5262\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3974 - MOC: 0.6211 - val_loss: 0.5123 - val_MOC: 0.5128\n",
      "60\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 444us/step - loss: 0.5323 - MOC: 0.4969 - val_loss: 0.4994 - val_MOC: 0.5274\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4955 - MOC: 0.5325 - val_loss: 0.4939 - val_MOC: 0.5337\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4779 - MOC: 0.5491 - val_loss: 0.4993 - val_MOC: 0.5274\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4638 - MOC: 0.5617 - val_loss: 0.4965 - val_MOC: 0.5304\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4510 - MOC: 0.5738 - val_loss: 0.4972 - val_MOC: 0.5301\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4383 - MOC: 0.5854 - val_loss: 0.4962 - val_MOC: 0.5311\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4298 - MOC: 0.5932 - val_loss: 0.5016 - val_MOC: 0.5250\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4189 - MOC: 0.6033 - val_loss: 0.5026 - val_MOC: 0.5240\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 421us/step - loss: 0.4110 - MOC: 0.6103 - val_loss: 0.5112 - val_MOC: 0.5148\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4016 - MOC: 0.6190 - val_loss: 0.5087 - val_MOC: 0.5177\n",
      "61\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 406us/step - loss: 0.5179 - MOC: 0.5093 - val_loss: 0.5019 - val_MOC: 0.5252\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4886 - MOC: 0.5376 - val_loss: 0.4965 - val_MOC: 0.5305\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4702 - MOC: 0.5547 - val_loss: 0.4980 - val_MOC: 0.5286\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4541 - MOC: 0.5696 - val_loss: 0.4885 - val_MOC: 0.5390\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4414 - MOC: 0.5815 - val_loss: 0.4944 - val_MOC: 0.5322\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 474us/step - loss: 0.4282 - MOC: 0.5937 - val_loss: 0.4922 - val_MOC: 0.5342\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4192 - MOC: 0.6018 - val_loss: 0.4958 - val_MOC: 0.5302\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4084 - MOC: 0.6118 - val_loss: 0.5003 - val_MOC: 0.5251\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3984 - MOC: 0.6211 - val_loss: 0.5062 - val_MOC: 0.5191\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3895 - MOC: 0.6292 - val_loss: 0.5076 - val_MOC: 0.5175\n",
      "62\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.5274 - MOC: 0.5002 - val_loss: 0.5046 - val_MOC: 0.5221\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4947 - MOC: 0.5318 - val_loss: 0.4951 - val_MOC: 0.5316\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4753 - MOC: 0.5497 - val_loss: 0.4912 - val_MOC: 0.5351\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4610 - MOC: 0.5631 - val_loss: 0.4888 - val_MOC: 0.5387\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4490 - MOC: 0.5743 - val_loss: 0.4920 - val_MOC: 0.5341\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4341 - MOC: 0.5879 - val_loss: 0.4973 - val_MOC: 0.5303\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4252 - MOC: 0.5961 - val_loss: 0.4998 - val_MOC: 0.5256\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4169 - MOC: 0.6037 - val_loss: 0.5001 - val_MOC: 0.5252\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4071 - MOC: 0.6128 - val_loss: 0.5065 - val_MOC: 0.5188\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.3976 - MOC: 0.6215 - val_loss: 0.5084 - val_MOC: 0.5164\n",
      "63\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5312 - MOC: 0.4965 - val_loss: 0.5011 - val_MOC: 0.5270\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4975 - MOC: 0.5293 - val_loss: 0.4986 - val_MOC: 0.5279\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4770 - MOC: 0.5483 - val_loss: 0.4982 - val_MOC: 0.5282\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4625 - MOC: 0.5620 - val_loss: 0.4993 - val_MOC: 0.5272\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4504 - MOC: 0.5731 - val_loss: 0.4993 - val_MOC: 0.5268\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 443us/step - loss: 0.4384 - MOC: 0.5841 - val_loss: 0.5033 - val_MOC: 0.5237\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4270 - MOC: 0.5946 - val_loss: 0.5046 - val_MOC: 0.5215\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4151 - MOC: 0.6057 - val_loss: 0.5100 - val_MOC: 0.5160\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4081 - MOC: 0.6120 - val_loss: 0.5125 - val_MOC: 0.5140\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3981 - MOC: 0.6212 - val_loss: 0.5139 - val_MOC: 0.5124\n",
      "64\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.5212 - MOC: 0.5058 - val_loss: 0.4995 - val_MOC: 0.5295\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4905 - MOC: 0.5357 - val_loss: 0.4970 - val_MOC: 0.5297\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.4681 - MOC: 0.5565 - val_loss: 0.5011 - val_MOC: 0.5257\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 439us/step - loss: 0.4544 - MOC: 0.5691 - val_loss: 0.4986 - val_MOC: 0.5276\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4408 - MOC: 0.5818 - val_loss: 0.5014 - val_MOC: 0.5244\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4300 - MOC: 0.5917 - val_loss: 0.5008 - val_MOC: 0.5254\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4181 - MOC: 0.6028 - val_loss: 0.5074 - val_MOC: 0.5177\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4092 - MOC: 0.6109 - val_loss: 0.5017 - val_MOC: 0.5238\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.3988 - MOC: 0.6205 - val_loss: 0.5039 - val_MOC: 0.5215\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.3911 - MOC: 0.6276 - val_loss: 0.5066 - val_MOC: 0.5188\n",
      "65\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 418us/step - loss: 0.5268 - MOC: 0.5014 - val_loss: 0.5095 - val_MOC: 0.5172\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4978 - MOC: 0.5296 - val_loss: 0.4970 - val_MOC: 0.5299\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4754 - MOC: 0.5504 - val_loss: 0.4991 - val_MOC: 0.5274\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4627 - MOC: 0.5622 - val_loss: 0.4982 - val_MOC: 0.5297\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4512 - MOC: 0.5728 - val_loss: 0.5070 - val_MOC: 0.5193\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4388 - MOC: 0.5842 - val_loss: 0.5102 - val_MOC: 0.5157\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4275 - MOC: 0.5947 - val_loss: 0.5131 - val_MOC: 0.5128\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4186 - MOC: 0.6028 - val_loss: 0.5095 - val_MOC: 0.5172\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 414us/step - loss: 0.4083 - MOC: 0.6123 - val_loss: 0.5076 - val_MOC: 0.5190\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4020 - MOC: 0.6181 - val_loss: 0.5135 - val_MOC: 0.5125\n",
      "66\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5198 - MOC: 0.5068 - val_loss: 0.5049 - val_MOC: 0.5221\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4915 - MOC: 0.5341 - val_loss: 0.4942 - val_MOC: 0.5334\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4723 - MOC: 0.5520 - val_loss: 0.4983 - val_MOC: 0.5292\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4590 - MOC: 0.5644 - val_loss: 0.4956 - val_MOC: 0.5313\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4439 - MOC: 0.5786 - val_loss: 0.4999 - val_MOC: 0.5266\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4338 - MOC: 0.5877 - val_loss: 0.5000 - val_MOC: 0.5267\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4208 - MOC: 0.5998 - val_loss: 0.5015 - val_MOC: 0.5247\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.4114 - MOC: 0.6084 - val_loss: 0.5185 - val_MOC: 0.5065\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.4036 - MOC: 0.6156 - val_loss: 0.5146 - val_MOC: 0.5110\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.3937 - MOC: 0.6248 - val_loss: 0.5196 - val_MOC: 0.5059\n",
      "67\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5247 - MOC: 0.5024 - val_loss: 0.5032 - val_MOC: 0.5249\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4926 - MOC: 0.5334 - val_loss: 0.4990 - val_MOC: 0.5281\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4739 - MOC: 0.5510 - val_loss: 0.4969 - val_MOC: 0.5295\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4596 - MOC: 0.5644 - val_loss: 0.4951 - val_MOC: 0.5320\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.4461 - MOC: 0.5768 - val_loss: 0.5011 - val_MOC: 0.5250\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4330 - MOC: 0.5889 - val_loss: 0.4997 - val_MOC: 0.5256\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4258 - MOC: 0.5953 - val_loss: 0.5032 - val_MOC: 0.5232\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4142 - MOC: 0.6062 - val_loss: 0.5038 - val_MOC: 0.5218\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4062 - MOC: 0.6136 - val_loss: 0.5154 - val_MOC: 0.5098\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.3974 - MOC: 0.6216 - val_loss: 0.5180 - val_MOC: 0.5064\n",
      "68\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.5347 - MOC: 0.4947 - val_loss: 0.5106 - val_MOC: 0.5172\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.5035 - MOC: 0.5249 - val_loss: 0.4892 - val_MOC: 0.5390\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4837 - MOC: 0.5432 - val_loss: 0.4931 - val_MOC: 0.5338\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4688 - MOC: 0.5572 - val_loss: 0.4880 - val_MOC: 0.5392\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4568 - MOC: 0.5682 - val_loss: 0.4930 - val_MOC: 0.5335\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4480 - MOC: 0.5762 - val_loss: 0.4985 - val_MOC: 0.5272\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4353 - MOC: 0.5878 - val_loss: 0.4939 - val_MOC: 0.5328\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 419us/step - loss: 0.4267 - MOC: 0.5957 - val_loss: 0.4970 - val_MOC: 0.5290\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.4159 - MOC: 0.6056 - val_loss: 0.4994 - val_MOC: 0.5271\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4080 - MOC: 0.6128 - val_loss: 0.5076 - val_MOC: 0.5187\n",
      "69\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.5192 - MOC: 0.5074 - val_loss: 0.5008 - val_MOC: 0.5261\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4905 - MOC: 0.5351 - val_loss: 0.4956 - val_MOC: 0.5321\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4711 - MOC: 0.5531 - val_loss: 0.4956 - val_MOC: 0.5314\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4582 - MOC: 0.5653 - val_loss: 0.4990 - val_MOC: 0.5276\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4448 - MOC: 0.5776 - val_loss: 0.4966 - val_MOC: 0.5295\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4337 - MOC: 0.5879 - val_loss: 0.5020 - val_MOC: 0.5238\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 445us/step - loss: 0.4226 - MOC: 0.5981 - val_loss: 0.5082 - val_MOC: 0.5169\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 407us/step - loss: 0.4126 - MOC: 0.6073 - val_loss: 0.5054 - val_MOC: 0.5204\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4038 - MOC: 0.6154 - val_loss: 0.5082 - val_MOC: 0.5172\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.3981 - MOC: 0.6206 - val_loss: 0.5093 - val_MOC: 0.5165\n",
      "70\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.5222 - MOC: 0.5057 - val_loss: 0.4933 - val_MOC: 0.5347\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4923 - MOC: 0.5345 - val_loss: 0.4942 - val_MOC: 0.5330\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4733 - MOC: 0.5523 - val_loss: 0.4933 - val_MOC: 0.5335\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4615 - MOC: 0.5634 - val_loss: 0.4919 - val_MOC: 0.5347\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.4479 - MOC: 0.5758 - val_loss: 0.4950 - val_MOC: 0.5316\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4358 - MOC: 0.5871 - val_loss: 0.4951 - val_MOC: 0.5313\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4254 - MOC: 0.5966 - val_loss: 0.4970 - val_MOC: 0.5289\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4164 - MOC: 0.6048 - val_loss: 0.5085 - val_MOC: 0.5174\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4081 - MOC: 0.6124 - val_loss: 0.5029 - val_MOC: 0.5234\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3989 - MOC: 0.6210 - val_loss: 0.5062 - val_MOC: 0.5196\n",
      "71\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5167 - MOC: 0.5095 - val_loss: 0.4908 - val_MOC: 0.5372\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4892 - MOC: 0.5361 - val_loss: 0.4944 - val_MOC: 0.5329\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4688 - MOC: 0.5553 - val_loss: 0.4935 - val_MOC: 0.5341\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4550 - MOC: 0.5683 - val_loss: 0.4967 - val_MOC: 0.5302\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.4433 - MOC: 0.5790 - val_loss: 0.5069 - val_MOC: 0.5200\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4304 - MOC: 0.5909 - val_loss: 0.5005 - val_MOC: 0.5261\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4204 - MOC: 0.6001 - val_loss: 0.5044 - val_MOC: 0.5226\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4105 - MOC: 0.6093 - val_loss: 0.5072 - val_MOC: 0.5192\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4005 - MOC: 0.6184 - val_loss: 0.5165 - val_MOC: 0.5099\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3942 - MOC: 0.6243 - val_loss: 0.5206 - val_MOC: 0.5051\n",
      "72\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.5232 - MOC: 0.5042 - val_loss: 0.5041 - val_MOC: 0.5230\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4958 - MOC: 0.5306 - val_loss: 0.5114 - val_MOC: 0.5154\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4805 - MOC: 0.5449 - val_loss: 0.4990 - val_MOC: 0.5290\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.4639 - MOC: 0.5605 - val_loss: 0.4960 - val_MOC: 0.5318\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4524 - MOC: 0.5711 - val_loss: 0.4953 - val_MOC: 0.5325\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4424 - MOC: 0.5802 - val_loss: 0.5005 - val_MOC: 0.5262\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4313 - MOC: 0.5906 - val_loss: 0.5053 - val_MOC: 0.5211\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4217 - MOC: 0.5994 - val_loss: 0.5048 - val_MOC: 0.5217\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4137 - MOC: 0.6068 - val_loss: 0.5120 - val_MOC: 0.5134\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4061 - MOC: 0.6138 - val_loss: 0.5116 - val_MOC: 0.5157\n",
      "73\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5211 - MOC: 0.5061 - val_loss: 0.4950 - val_MOC: 0.5342\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4897 - MOC: 0.5365 - val_loss: 0.4940 - val_MOC: 0.5338\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4724 - MOC: 0.5526 - val_loss: 0.4960 - val_MOC: 0.5313\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4587 - MOC: 0.5654 - val_loss: 0.5033 - val_MOC: 0.5233\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.4473 - MOC: 0.5759 - val_loss: 0.4953 - val_MOC: 0.5323\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 418us/step - loss: 0.4355 - MOC: 0.5869 - val_loss: 0.4987 - val_MOC: 0.5288\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4252 - MOC: 0.5963 - val_loss: 0.5037 - val_MOC: 0.5239\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4161 - MOC: 0.6047 - val_loss: 0.5057 - val_MOC: 0.5205\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4060 - MOC: 0.6141 - val_loss: 0.5030 - val_MOC: 0.5237\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3966 - MOC: 0.6227 - val_loss: 0.5124 - val_MOC: 0.5138\n",
      "74\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 439us/step - loss: 0.5193 - MOC: 0.5072 - val_loss: 0.4989 - val_MOC: 0.5300\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4898 - MOC: 0.5360 - val_loss: 0.4949 - val_MOC: 0.5329\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4679 - MOC: 0.5564 - val_loss: 0.4978 - val_MOC: 0.5289\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4568 - MOC: 0.5666 - val_loss: 0.4951 - val_MOC: 0.5322\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4443 - MOC: 0.5782 - val_loss: 0.5020 - val_MOC: 0.5241\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4317 - MOC: 0.5899 - val_loss: 0.5043 - val_MOC: 0.5217\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4225 - MOC: 0.5982 - val_loss: 0.5066 - val_MOC: 0.5197\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4111 - MOC: 0.6090 - val_loss: 0.5068 - val_MOC: 0.5192\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4027 - MOC: 0.6166 - val_loss: 0.5095 - val_MOC: 0.5162\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3941 - MOC: 0.6247 - val_loss: 0.5074 - val_MOC: 0.5192\n",
      "75\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.5268 - MOC: 0.5008 - val_loss: 0.5020 - val_MOC: 0.5253\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4940 - MOC: 0.5324 - val_loss: 0.4955 - val_MOC: 0.5315\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4768 - MOC: 0.5486 - val_loss: 0.4937 - val_MOC: 0.5331\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4634 - MOC: 0.5610 - val_loss: 0.4943 - val_MOC: 0.5325\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4531 - MOC: 0.5704 - val_loss: 0.4990 - val_MOC: 0.5271\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4406 - MOC: 0.5820 - val_loss: 0.5030 - val_MOC: 0.5235\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4300 - MOC: 0.5918 - val_loss: 0.5028 - val_MOC: 0.5241\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4205 - MOC: 0.6005 - val_loss: 0.5133 - val_MOC: 0.5118\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4126 - MOC: 0.6077 - val_loss: 0.5120 - val_MOC: 0.5137\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4049 - MOC: 0.6148 - val_loss: 0.5145 - val_MOC: 0.5111\n",
      "76\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 448us/step - loss: 0.5242 - MOC: 0.5039 - val_loss: 0.4998 - val_MOC: 0.5280\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4944 - MOC: 0.5327 - val_loss: 0.4910 - val_MOC: 0.5368\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4753 - MOC: 0.5507 - val_loss: 0.4967 - val_MOC: 0.5305\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4610 - MOC: 0.5639 - val_loss: 0.5001 - val_MOC: 0.5265\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4495 - MOC: 0.5744 - val_loss: 0.5015 - val_MOC: 0.5248\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4390 - MOC: 0.5842 - val_loss: 0.4987 - val_MOC: 0.5292\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4304 - MOC: 0.5922 - val_loss: 0.5008 - val_MOC: 0.5263\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4217 - MOC: 0.6001 - val_loss: 0.5044 - val_MOC: 0.5221\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4102 - MOC: 0.6107 - val_loss: 0.5082 - val_MOC: 0.5185\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4026 - MOC: 0.6177 - val_loss: 0.5185 - val_MOC: 0.5079\n",
      "77\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 455us/step - loss: 0.5097 - MOC: 0.5160 - val_loss: 0.5062 - val_MOC: 0.5218\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4825 - MOC: 0.5423 - val_loss: 0.5059 - val_MOC: 0.5213\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4653 - MOC: 0.5583 - val_loss: 0.5148 - val_MOC: 0.5118\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4536 - MOC: 0.5692 - val_loss: 0.5102 - val_MOC: 0.5167\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4404 - MOC: 0.5814 - val_loss: 0.5046 - val_MOC: 0.5226\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4293 - MOC: 0.5917 - val_loss: 0.5100 - val_MOC: 0.5169\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4177 - MOC: 0.6025 - val_loss: 0.5196 - val_MOC: 0.5068\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4075 - MOC: 0.6120 - val_loss: 0.5193 - val_MOC: 0.5077\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4016 - MOC: 0.6172 - val_loss: 0.5194 - val_MOC: 0.5069\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3913 - MOC: 0.6268 - val_loss: 0.5265 - val_MOC: 0.4988\n",
      "78\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.5200 - MOC: 0.5065 - val_loss: 0.5055 - val_MOC: 0.5221\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4893 - MOC: 0.5364 - val_loss: 0.4975 - val_MOC: 0.5305\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4714 - MOC: 0.5532 - val_loss: 0.4960 - val_MOC: 0.5318\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.4570 - MOC: 0.5666 - val_loss: 0.4880 - val_MOC: 0.5394\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.4456 - MOC: 0.5772 - val_loss: 0.5004 - val_MOC: 0.5264\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4357 - MOC: 0.5862 - val_loss: 0.5097 - val_MOC: 0.5157\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4222 - MOC: 0.5989 - val_loss: 0.4957 - val_MOC: 0.5311\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4140 - MOC: 0.6064 - val_loss: 0.4987 - val_MOC: 0.5274\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4046 - MOC: 0.6151 - val_loss: 0.5041 - val_MOC: 0.5213\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3953 - MOC: 0.6237 - val_loss: 0.5071 - val_MOC: 0.5180\n",
      "79\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 453us/step - loss: 0.5137 - MOC: 0.5131 - val_loss: 0.4966 - val_MOC: 0.5309\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4837 - MOC: 0.5420 - val_loss: 0.5006 - val_MOC: 0.5260\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4665 - MOC: 0.5581 - val_loss: 0.4951 - val_MOC: 0.5312\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4517 - MOC: 0.5718 - val_loss: 0.4931 - val_MOC: 0.5337\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4400 - MOC: 0.5828 - val_loss: 0.5072 - val_MOC: 0.5179\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4293 - MOC: 0.5924 - val_loss: 0.5064 - val_MOC: 0.5191\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4191 - MOC: 0.6020 - val_loss: 0.4971 - val_MOC: 0.5293\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4096 - MOC: 0.6107 - val_loss: 0.5102 - val_MOC: 0.5152\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4017 - MOC: 0.6179 - val_loss: 0.5062 - val_MOC: 0.5191\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.3924 - MOC: 0.6265 - val_loss: 0.5074 - val_MOC: 0.5180\n",
      "80\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.5223 - MOC: 0.5040 - val_loss: 0.5033 - val_MOC: 0.5252\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4918 - MOC: 0.5336 - val_loss: 0.4966 - val_MOC: 0.5307\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4736 - MOC: 0.5508 - val_loss: 0.5011 - val_MOC: 0.5266\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4634 - MOC: 0.5602 - val_loss: 0.5052 - val_MOC: 0.5216\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4489 - MOC: 0.5737 - val_loss: 0.5031 - val_MOC: 0.5244\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4388 - MOC: 0.5831 - val_loss: 0.5066 - val_MOC: 0.5206\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4279 - MOC: 0.5932 - val_loss: 0.5058 - val_MOC: 0.5217\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 436us/step - loss: 0.4175 - MOC: 0.6028 - val_loss: 0.5089 - val_MOC: 0.5178\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4111 - MOC: 0.6086 - val_loss: 0.5143 - val_MOC: 0.5127\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4002 - MOC: 0.6187 - val_loss: 0.5132 - val_MOC: 0.5137\n",
      "81\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.5214 - MOC: 0.5065 - val_loss: 0.5033 - val_MOC: 0.5237\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4928 - MOC: 0.5341 - val_loss: 0.4955 - val_MOC: 0.5316\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4776 - MOC: 0.5483 - val_loss: 0.4879 - val_MOC: 0.5393\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4638 - MOC: 0.5613 - val_loss: 0.4998 - val_MOC: 0.5261\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4504 - MOC: 0.5736 - val_loss: 0.4898 - val_MOC: 0.5371\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4399 - MOC: 0.5833 - val_loss: 0.4934 - val_MOC: 0.5335\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4314 - MOC: 0.5910 - val_loss: 0.4932 - val_MOC: 0.5333\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4192 - MOC: 0.6023 - val_loss: 0.4924 - val_MOC: 0.5342\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4136 - MOC: 0.6074 - val_loss: 0.4997 - val_MOC: 0.5257\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4026 - MOC: 0.6175 - val_loss: 0.4928 - val_MOC: 0.5333\n",
      "82\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.5156 - MOC: 0.5121 - val_loss: 0.4898 - val_MOC: 0.5378\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4882 - MOC: 0.5386 - val_loss: 0.4798 - val_MOC: 0.5469\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4724 - MOC: 0.5533 - val_loss: 0.4842 - val_MOC: 0.5425\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4570 - MOC: 0.5675 - val_loss: 0.4871 - val_MOC: 0.5394\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4468 - MOC: 0.5768 - val_loss: 0.4866 - val_MOC: 0.5393\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4343 - MOC: 0.5884 - val_loss: 0.4879 - val_MOC: 0.5385\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4254 - MOC: 0.5965 - val_loss: 0.5026 - val_MOC: 0.5221\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4163 - MOC: 0.6050 - val_loss: 0.4891 - val_MOC: 0.5365\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 429us/step - loss: 0.4064 - MOC: 0.6142 - val_loss: 0.5000 - val_MOC: 0.5253\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.3955 - MOC: 0.6241 - val_loss: 0.5019 - val_MOC: 0.5227\n",
      "83\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5179 - MOC: 0.5086 - val_loss: 0.4859 - val_MOC: 0.5406\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4891 - MOC: 0.5367 - val_loss: 0.4881 - val_MOC: 0.5378\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4727 - MOC: 0.5517 - val_loss: 0.4803 - val_MOC: 0.5469\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4604 - MOC: 0.5632 - val_loss: 0.4816 - val_MOC: 0.5451\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4480 - MOC: 0.5747 - val_loss: 0.4846 - val_MOC: 0.5410\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4358 - MOC: 0.5861 - val_loss: 0.4853 - val_MOC: 0.5409\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 425us/step - loss: 0.4249 - MOC: 0.5962 - val_loss: 0.4879 - val_MOC: 0.5378\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4168 - MOC: 0.6036 - val_loss: 0.4960 - val_MOC: 0.5288\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4082 - MOC: 0.6116 - val_loss: 0.5034 - val_MOC: 0.5210\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3989 - MOC: 0.6201 - val_loss: 0.5017 - val_MOC: 0.5228\n",
      "84\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5120 - MOC: 0.5148 - val_loss: 0.4966 - val_MOC: 0.5308\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4818 - MOC: 0.5440 - val_loss: 0.4962 - val_MOC: 0.5307\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4665 - MOC: 0.5586 - val_loss: 0.4922 - val_MOC: 0.5343\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4508 - MOC: 0.5730 - val_loss: 0.4907 - val_MOC: 0.5354\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4389 - MOC: 0.5841 - val_loss: 0.4967 - val_MOC: 0.5301\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4295 - MOC: 0.5927 - val_loss: 0.4964 - val_MOC: 0.5296\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4188 - MOC: 0.6026 - val_loss: 0.4903 - val_MOC: 0.5359\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4106 - MOC: 0.6102 - val_loss: 0.5008 - val_MOC: 0.5242\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4023 - MOC: 0.6178 - val_loss: 0.5037 - val_MOC: 0.5212\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 426us/step - loss: 0.3921 - MOC: 0.6272 - val_loss: 0.4981 - val_MOC: 0.5280\n",
      "85\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5170 - MOC: 0.5085 - val_loss: 0.4941 - val_MOC: 0.5335\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4863 - MOC: 0.5384 - val_loss: 0.4925 - val_MOC: 0.5345\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4729 - MOC: 0.5511 - val_loss: 0.4944 - val_MOC: 0.5317\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4569 - MOC: 0.5660 - val_loss: 0.4974 - val_MOC: 0.5285\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4465 - MOC: 0.5756 - val_loss: 0.4862 - val_MOC: 0.5407\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 436us/step - loss: 0.4329 - MOC: 0.5883 - val_loss: 0.4968 - val_MOC: 0.5293\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 423us/step - loss: 0.4253 - MOC: 0.5952 - val_loss: 0.4985 - val_MOC: 0.5274\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4145 - MOC: 0.6053 - val_loss: 0.5017 - val_MOC: 0.5238\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4077 - MOC: 0.6114 - val_loss: 0.5072 - val_MOC: 0.5183\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3977 - MOC: 0.6208 - val_loss: 0.5114 - val_MOC: 0.5126\n",
      "86\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.5189 - MOC: 0.5069 - val_loss: 0.4943 - val_MOC: 0.5325\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4895 - MOC: 0.5355 - val_loss: 0.4952 - val_MOC: 0.5311\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4723 - MOC: 0.5516 - val_loss: 0.4929 - val_MOC: 0.5337\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 417us/step - loss: 0.4602 - MOC: 0.5628 - val_loss: 0.4904 - val_MOC: 0.5365\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4469 - MOC: 0.5752 - val_loss: 0.4898 - val_MOC: 0.5365\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4358 - MOC: 0.5854 - val_loss: 0.4930 - val_MOC: 0.5342\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4252 - MOC: 0.5953 - val_loss: 0.5015 - val_MOC: 0.5240\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4162 - MOC: 0.6037 - val_loss: 0.4967 - val_MOC: 0.5296\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4101 - MOC: 0.6092 - val_loss: 0.5016 - val_MOC: 0.5241\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4020 - MOC: 0.6167 - val_loss: 0.5024 - val_MOC: 0.5241\n",
      "87\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 432us/step - loss: 0.5118 - MOC: 0.5147 - val_loss: 0.4992 - val_MOC: 0.5273\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4838 - MOC: 0.5418 - val_loss: 0.4921 - val_MOC: 0.5351\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4677 - MOC: 0.5570 - val_loss: 0.4861 - val_MOC: 0.5403\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4518 - MOC: 0.5716 - val_loss: 0.4872 - val_MOC: 0.5389\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4396 - MOC: 0.5829 - val_loss: 0.4860 - val_MOC: 0.5397\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4297 - MOC: 0.5920 - val_loss: 0.4902 - val_MOC: 0.5352\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4178 - MOC: 0.6031 - val_loss: 0.4908 - val_MOC: 0.5347\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4103 - MOC: 0.6100 - val_loss: 0.4937 - val_MOC: 0.5316\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4005 - MOC: 0.6190 - val_loss: 0.4938 - val_MOC: 0.5319\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3946 - MOC: 0.6245 - val_loss: 0.4972 - val_MOC: 0.5279\n",
      "88\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 2s 455us/step - loss: 0.5173 - MOC: 0.5103 - val_loss: 0.4874 - val_MOC: 0.5392\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4897 - MOC: 0.5371 - val_loss: 0.4833 - val_MOC: 0.5426\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4721 - MOC: 0.5536 - val_loss: 0.4827 - val_MOC: 0.5431\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4595 - MOC: 0.5651 - val_loss: 0.4804 - val_MOC: 0.5452\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4485 - MOC: 0.5754 - val_loss: 0.4841 - val_MOC: 0.5407\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4365 - MOC: 0.5864 - val_loss: 0.4877 - val_MOC: 0.5369\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4272 - MOC: 0.5952 - val_loss: 0.4916 - val_MOC: 0.5333\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4180 - MOC: 0.6035 - val_loss: 0.4900 - val_MOC: 0.5347\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4103 - MOC: 0.6106 - val_loss: 0.4926 - val_MOC: 0.5324\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4038 - MOC: 0.6165 - val_loss: 0.5004 - val_MOC: 0.5240\n",
      "89\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 475us/step - loss: 0.5149 - MOC: 0.5121 - val_loss: 0.4870 - val_MOC: 0.5406\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4892 - MOC: 0.5369 - val_loss: 0.4842 - val_MOC: 0.5427\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4732 - MOC: 0.5517 - val_loss: 0.4951 - val_MOC: 0.5314\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4580 - MOC: 0.5658 - val_loss: 0.4944 - val_MOC: 0.5314\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4468 - MOC: 0.5764 - val_loss: 0.4913 - val_MOC: 0.5347\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4380 - MOC: 0.5844 - val_loss: 0.4916 - val_MOC: 0.5343\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4273 - MOC: 0.5942 - val_loss: 0.4932 - val_MOC: 0.5331\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4184 - MOC: 0.6024 - val_loss: 0.4911 - val_MOC: 0.5349\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4069 - MOC: 0.6132 - val_loss: 0.4983 - val_MOC: 0.5271\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.3996 - MOC: 0.6198 - val_loss: 0.5088 - val_MOC: 0.5155\n",
      "90\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 412us/step - loss: 0.5200 - MOC: 0.5074 - val_loss: 0.4976 - val_MOC: 0.5289\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4931 - MOC: 0.5337 - val_loss: 0.4837 - val_MOC: 0.5446\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4766 - MOC: 0.5491 - val_loss: 0.4942 - val_MOC: 0.5317\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4636 - MOC: 0.5613 - val_loss: 0.4895 - val_MOC: 0.5364\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4513 - MOC: 0.5726 - val_loss: 0.5009 - val_MOC: 0.5242\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 377us/step - loss: 0.4401 - MOC: 0.5829 - val_loss: 0.4922 - val_MOC: 0.5341\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4309 - MOC: 0.5913 - val_loss: 0.4955 - val_MOC: 0.5307\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4214 - MOC: 0.6000 - val_loss: 0.4942 - val_MOC: 0.5308\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4130 - MOC: 0.6077 - val_loss: 0.5010 - val_MOC: 0.5260\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4070 - MOC: 0.6132 - val_loss: 0.5093 - val_MOC: 0.5166\n",
      "91\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.5145 - MOC: 0.5114 - val_loss: 0.4899 - val_MOC: 0.5374\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4841 - MOC: 0.5406 - val_loss: 0.4926 - val_MOC: 0.5340\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4684 - MOC: 0.5555 - val_loss: 0.4930 - val_MOC: 0.5333\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4552 - MOC: 0.5677 - val_loss: 0.4899 - val_MOC: 0.5366\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4428 - MOC: 0.5793 - val_loss: 0.4946 - val_MOC: 0.5310\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.4324 - MOC: 0.5888 - val_loss: 0.4951 - val_MOC: 0.5300\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.4215 - MOC: 0.5990 - val_loss: 0.4969 - val_MOC: 0.5290\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4115 - MOC: 0.6082 - val_loss: 0.5007 - val_MOC: 0.5246\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4038 - MOC: 0.6153 - val_loss: 0.5002 - val_MOC: 0.5257\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3964 - MOC: 0.6221 - val_loss: 0.5014 - val_MOC: 0.5247\n",
      "92\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5124 - MOC: 0.5149 - val_loss: 0.5009 - val_MOC: 0.5252\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4852 - MOC: 0.5412 - val_loss: 0.4891 - val_MOC: 0.5371\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4693 - MOC: 0.5560 - val_loss: 0.4842 - val_MOC: 0.5422\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4582 - MOC: 0.5663 - val_loss: 0.4850 - val_MOC: 0.5415\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 432us/step - loss: 0.4455 - MOC: 0.5782 - val_loss: 0.4943 - val_MOC: 0.5322\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4356 - MOC: 0.5874 - val_loss: 0.4901 - val_MOC: 0.5362\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4284 - MOC: 0.5937 - val_loss: 0.4898 - val_MOC: 0.5370\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4178 - MOC: 0.6036 - val_loss: 0.4975 - val_MOC: 0.5282\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4082 - MOC: 0.6125 - val_loss: 0.5017 - val_MOC: 0.5234\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4011 - MOC: 0.6189 - val_loss: 0.5036 - val_MOC: 0.5217\n",
      "93\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.5209 - MOC: 0.5082 - val_loss: 0.4973 - val_MOC: 0.5298\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4915 - MOC: 0.5364 - val_loss: 0.4876 - val_MOC: 0.5390\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4762 - MOC: 0.5508 - val_loss: 0.4875 - val_MOC: 0.5391\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.4649 - MOC: 0.5610 - val_loss: 0.4884 - val_MOC: 0.5387\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.4508 - MOC: 0.5741 - val_loss: 0.4940 - val_MOC: 0.5323\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4426 - MOC: 0.5817 - val_loss: 0.4970 - val_MOC: 0.5297\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4329 - MOC: 0.5905 - val_loss: 0.4956 - val_MOC: 0.5313\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4233 - MOC: 0.5993 - val_loss: 0.5053 - val_MOC: 0.5197\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4143 - MOC: 0.6074 - val_loss: 0.4993 - val_MOC: 0.5265\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4090 - MOC: 0.6122 - val_loss: 0.5052 - val_MOC: 0.5205\n",
      "94\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5157 - MOC: 0.5103 - val_loss: 0.4906 - val_MOC: 0.5362\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4845 - MOC: 0.5405 - val_loss: 0.4853 - val_MOC: 0.5414\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4660 - MOC: 0.5579 - val_loss: 0.4845 - val_MOC: 0.5419\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 428us/step - loss: 0.4544 - MOC: 0.5687 - val_loss: 0.4839 - val_MOC: 0.5427\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.4417 - MOC: 0.5805 - val_loss: 0.4884 - val_MOC: 0.5369\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4321 - MOC: 0.5894 - val_loss: 0.4897 - val_MOC: 0.5362\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4215 - MOC: 0.5992 - val_loss: 0.4902 - val_MOC: 0.5350\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4116 - MOC: 0.6083 - val_loss: 0.4948 - val_MOC: 0.5302\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4033 - MOC: 0.6161 - val_loss: 0.4980 - val_MOC: 0.5276\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3946 - MOC: 0.6240 - val_loss: 0.4966 - val_MOC: 0.5288\n",
      "95\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5177 - MOC: 0.5084 - val_loss: 0.4926 - val_MOC: 0.5347\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4883 - MOC: 0.5369 - val_loss: 0.4896 - val_MOC: 0.5383\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4727 - MOC: 0.5515 - val_loss: 0.4941 - val_MOC: 0.5319\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.4587 - MOC: 0.5646 - val_loss: 0.4863 - val_MOC: 0.5406\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.4467 - MOC: 0.5757 - val_loss: 0.4950 - val_MOC: 0.5311\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4364 - MOC: 0.5853 - val_loss: 0.4921 - val_MOC: 0.5339\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4261 - MOC: 0.5948 - val_loss: 0.4982 - val_MOC: 0.5284\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4206 - MOC: 0.5998 - val_loss: 0.5125 - val_MOC: 0.5123\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4098 - MOC: 0.6098 - val_loss: 0.4983 - val_MOC: 0.5285\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3999 - MOC: 0.6191 - val_loss: 0.5098 - val_MOC: 0.5158\n",
      "96\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.5159 - MOC: 0.5105 - val_loss: 0.4928 - val_MOC: 0.5347\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4875 - MOC: 0.5381 - val_loss: 0.4898 - val_MOC: 0.5382\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4722 - MOC: 0.5524 - val_loss: 0.4974 - val_MOC: 0.5294\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 431us/step - loss: 0.4605 - MOC: 0.5632 - val_loss: 0.4955 - val_MOC: 0.5312\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.4452 - MOC: 0.5776 - val_loss: 0.4903 - val_MOC: 0.5367\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4350 - MOC: 0.5868 - val_loss: 0.4977 - val_MOC: 0.5285\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4249 - MOC: 0.5962 - val_loss: 0.5004 - val_MOC: 0.5261\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4152 - MOC: 0.6053 - val_loss: 0.5017 - val_MOC: 0.5240\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4089 - MOC: 0.6107 - val_loss: 0.5061 - val_MOC: 0.5198\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4009 - MOC: 0.6183 - val_loss: 0.5089 - val_MOC: 0.5166\n",
      "97\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5135 - MOC: 0.5120 - val_loss: 0.5013 - val_MOC: 0.5256\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4875 - MOC: 0.5372 - val_loss: 0.5022 - val_MOC: 0.5241\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4689 - MOC: 0.5548 - val_loss: 0.4900 - val_MOC: 0.5372\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.4546 - MOC: 0.5681 - val_loss: 0.4953 - val_MOC: 0.5308\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4436 - MOC: 0.5783 - val_loss: 0.4992 - val_MOC: 0.5264\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4347 - MOC: 0.5865 - val_loss: 0.4978 - val_MOC: 0.5282\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 435us/step - loss: 0.4226 - MOC: 0.5978 - val_loss: 0.5039 - val_MOC: 0.5215\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4153 - MOC: 0.6045 - val_loss: 0.5005 - val_MOC: 0.5252\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4052 - MOC: 0.6139 - val_loss: 0.5110 - val_MOC: 0.5141\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.3976 - MOC: 0.6207 - val_loss: 0.5110 - val_MOC: 0.5140\n",
      "98\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.5176 - MOC: 0.5102 - val_loss: 0.4934 - val_MOC: 0.5337\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4890 - MOC: 0.5378 - val_loss: 0.4900 - val_MOC: 0.5369\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4743 - MOC: 0.5516 - val_loss: 0.4841 - val_MOC: 0.5425\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4614 - MOC: 0.5636 - val_loss: 0.4864 - val_MOC: 0.5396\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 423us/step - loss: 0.4523 - MOC: 0.5719 - val_loss: 0.4831 - val_MOC: 0.5437\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 429us/step - loss: 0.4388 - MOC: 0.5844 - val_loss: 0.4855 - val_MOC: 0.5397\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4325 - MOC: 0.5901 - val_loss: 0.4828 - val_MOC: 0.5435\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4215 - MOC: 0.6003 - val_loss: 0.4875 - val_MOC: 0.5385\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4136 - MOC: 0.6075 - val_loss: 0.4897 - val_MOC: 0.5358\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4047 - MOC: 0.6158 - val_loss: 0.4921 - val_MOC: 0.5341\n",
      "99\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 454us/step - loss: 0.5118 - MOC: 0.5142 - val_loss: 0.4853 - val_MOC: 0.5418\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4849 - MOC: 0.5401 - val_loss: 0.4874 - val_MOC: 0.5396\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4652 - MOC: 0.5585 - val_loss: 0.4838 - val_MOC: 0.5423\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4533 - MOC: 0.5696 - val_loss: 0.4883 - val_MOC: 0.5380\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4411 - MOC: 0.5808 - val_loss: 0.4904 - val_MOC: 0.5359\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4328 - MOC: 0.5887 - val_loss: 0.4945 - val_MOC: 0.5316\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4232 - MOC: 0.5974 - val_loss: 0.4983 - val_MOC: 0.5276\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4121 - MOC: 0.6078 - val_loss: 0.5039 - val_MOC: 0.5214\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4029 - MOC: 0.6163 - val_loss: 0.5027 - val_MOC: 0.5222\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4001 - MOC: 0.6187 - val_loss: 0.5135 - val_MOC: 0.5121\n",
      "100\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 449us/step - loss: 0.5181 - MOC: 0.5087 - val_loss: 0.4948 - val_MOC: 0.5318\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4897 - MOC: 0.5364 - val_loss: 0.4905 - val_MOC: 0.5360\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4708 - MOC: 0.5542 - val_loss: 0.4866 - val_MOC: 0.5401\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4580 - MOC: 0.5660 - val_loss: 0.4894 - val_MOC: 0.5364\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4479 - MOC: 0.5753 - val_loss: 0.4888 - val_MOC: 0.5374\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4368 - MOC: 0.5855 - val_loss: 0.4969 - val_MOC: 0.5285\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4265 - MOC: 0.5951 - val_loss: 0.4944 - val_MOC: 0.5313\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 408us/step - loss: 0.4158 - MOC: 0.6050 - val_loss: 0.4985 - val_MOC: 0.5275\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 420us/step - loss: 0.4080 - MOC: 0.6122 - val_loss: 0.5010 - val_MOC: 0.5253\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4011 - MOC: 0.6186 - val_loss: 0.5015 - val_MOC: 0.5240\n",
      "101\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.5153 - MOC: 0.5120 - val_loss: 0.4919 - val_MOC: 0.5350\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4900 - MOC: 0.5367 - val_loss: 0.4876 - val_MOC: 0.5388\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4736 - MOC: 0.5519 - val_loss: 0.4868 - val_MOC: 0.5403\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 450us/step - loss: 0.4611 - MOC: 0.5636 - val_loss: 0.4897 - val_MOC: 0.5363\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4507 - MOC: 0.5732 - val_loss: 0.4896 - val_MOC: 0.5371\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4419 - MOC: 0.5813 - val_loss: 0.4904 - val_MOC: 0.5358\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4316 - MOC: 0.5906 - val_loss: 0.4913 - val_MOC: 0.5354\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4239 - MOC: 0.5979 - val_loss: 0.4927 - val_MOC: 0.5327\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4136 - MOC: 0.6073 - val_loss: 0.4981 - val_MOC: 0.5269\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4063 - MOC: 0.6141 - val_loss: 0.4967 - val_MOC: 0.5287\n",
      "102\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5139 - MOC: 0.5125 - val_loss: 0.4860 - val_MOC: 0.5408\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4877 - MOC: 0.5382 - val_loss: 0.4856 - val_MOC: 0.5406\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4698 - MOC: 0.5549 - val_loss: 0.4790 - val_MOC: 0.5471\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4585 - MOC: 0.5654 - val_loss: 0.4793 - val_MOC: 0.5466\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4469 - MOC: 0.5762 - val_loss: 0.4765 - val_MOC: 0.5496\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 424us/step - loss: 0.4372 - MOC: 0.5851 - val_loss: 0.4778 - val_MOC: 0.5487\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4258 - MOC: 0.5957 - val_loss: 0.4825 - val_MOC: 0.5435\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4177 - MOC: 0.6032 - val_loss: 0.4862 - val_MOC: 0.5392\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4087 - MOC: 0.6114 - val_loss: 0.4882 - val_MOC: 0.5371\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4016 - MOC: 0.6181 - val_loss: 0.4941 - val_MOC: 0.5306\n",
      "103\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5189 - MOC: 0.5088 - val_loss: 0.4908 - val_MOC: 0.5362\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4925 - MOC: 0.5344 - val_loss: 0.4869 - val_MOC: 0.5404\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4767 - MOC: 0.5492 - val_loss: 0.4870 - val_MOC: 0.5399\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4641 - MOC: 0.5609 - val_loss: 0.4918 - val_MOC: 0.5339\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4538 - MOC: 0.5703 - val_loss: 0.4926 - val_MOC: 0.5331\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4459 - MOC: 0.5776 - val_loss: 0.4950 - val_MOC: 0.5305\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 2s 434us/step - loss: 0.4341 - MOC: 0.5886 - val_loss: 0.4919 - val_MOC: 0.5339\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 424us/step - loss: 0.4265 - MOC: 0.5955 - val_loss: 0.4988 - val_MOC: 0.5263\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4198 - MOC: 0.6016 - val_loss: 0.4941 - val_MOC: 0.5322\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4103 - MOC: 0.6105 - val_loss: 0.4994 - val_MOC: 0.5266\n",
      "104\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5076 - MOC: 0.5190 - val_loss: 0.4888 - val_MOC: 0.5385\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4825 - MOC: 0.5433 - val_loss: 0.4865 - val_MOC: 0.5392\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4694 - MOC: 0.5555 - val_loss: 0.4845 - val_MOC: 0.5424\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 431us/step - loss: 0.4561 - MOC: 0.5680 - val_loss: 0.4824 - val_MOC: 0.5443\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 420us/step - loss: 0.4440 - MOC: 0.5793 - val_loss: 0.4872 - val_MOC: 0.5386\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4346 - MOC: 0.5877 - val_loss: 0.4853 - val_MOC: 0.5399\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4251 - MOC: 0.5967 - val_loss: 0.4858 - val_MOC: 0.5399\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4179 - MOC: 0.6031 - val_loss: 0.4856 - val_MOC: 0.5397\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4093 - MOC: 0.6112 - val_loss: 0.4917 - val_MOC: 0.5330\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4001 - MOC: 0.6195 - val_loss: 0.4956 - val_MOC: 0.5293\n",
      "105\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 431us/step - loss: 0.5078 - MOC: 0.5178 - val_loss: 0.4864 - val_MOC: 0.5402\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4818 - MOC: 0.5429 - val_loss: 0.4814 - val_MOC: 0.5448\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4669 - MOC: 0.5569 - val_loss: 0.4866 - val_MOC: 0.5390\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4540 - MOC: 0.5690 - val_loss: 0.4878 - val_MOC: 0.5377\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4431 - MOC: 0.5791 - val_loss: 0.4890 - val_MOC: 0.5359\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4329 - MOC: 0.5885 - val_loss: 0.4859 - val_MOC: 0.5398\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4239 - MOC: 0.5969 - val_loss: 0.4976 - val_MOC: 0.5276\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4175 - MOC: 0.6027 - val_loss: 0.4922 - val_MOC: 0.5338\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4071 - MOC: 0.6123 - val_loss: 0.4961 - val_MOC: 0.5291\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3988 - MOC: 0.6201 - val_loss: 0.4923 - val_MOC: 0.5347\n",
      "106\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 419us/step - loss: 0.5082 - MOC: 0.5180 - val_loss: 0.4942 - val_MOC: 0.5325\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4828 - MOC: 0.5426 - val_loss: 0.4891 - val_MOC: 0.5377\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4681 - MOC: 0.5564 - val_loss: 0.4802 - val_MOC: 0.5461\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4526 - MOC: 0.5708 - val_loss: 0.4841 - val_MOC: 0.5424\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4422 - MOC: 0.5806 - val_loss: 0.4889 - val_MOC: 0.5364\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4328 - MOC: 0.5891 - val_loss: 0.4904 - val_MOC: 0.5343\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4244 - MOC: 0.5968 - val_loss: 0.4832 - val_MOC: 0.5422\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4143 - MOC: 0.6062 - val_loss: 0.4897 - val_MOC: 0.5353\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4036 - MOC: 0.6161 - val_loss: 0.4854 - val_MOC: 0.5393\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3989 - MOC: 0.6204 - val_loss: 0.4872 - val_MOC: 0.5373\n",
      "107\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 425us/step - loss: 0.5054 - MOC: 0.5204 - val_loss: 0.4869 - val_MOC: 0.5396\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4785 - MOC: 0.5464 - val_loss: 0.4797 - val_MOC: 0.5466\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4643 - MOC: 0.5598 - val_loss: 0.4840 - val_MOC: 0.5416\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4524 - MOC: 0.5706 - val_loss: 0.4795 - val_MOC: 0.5465\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4395 - MOC: 0.5829 - val_loss: 0.4838 - val_MOC: 0.5418\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4296 - MOC: 0.5919 - val_loss: 0.4922 - val_MOC: 0.5326\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4203 - MOC: 0.6005 - val_loss: 0.4868 - val_MOC: 0.5390\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4117 - MOC: 0.6085 - val_loss: 0.4934 - val_MOC: 0.5315\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4027 - MOC: 0.6168 - val_loss: 0.4927 - val_MOC: 0.5322\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.3953 - MOC: 0.6236 - val_loss: 0.4944 - val_MOC: 0.5307\n",
      "108\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5013 - MOC: 0.5240 - val_loss: 0.4901 - val_MOC: 0.5364\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4752 - MOC: 0.5492 - val_loss: 0.4813 - val_MOC: 0.5449\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4582 - MOC: 0.5650 - val_loss: 0.4823 - val_MOC: 0.5431\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4448 - MOC: 0.5775 - val_loss: 0.4791 - val_MOC: 0.5463\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 419us/step - loss: 0.4346 - MOC: 0.5871 - val_loss: 0.4815 - val_MOC: 0.5440\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4263 - MOC: 0.5947 - val_loss: 0.4875 - val_MOC: 0.5372\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4165 - MOC: 0.6038 - val_loss: 0.4929 - val_MOC: 0.5314\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4087 - MOC: 0.6110 - val_loss: 0.4922 - val_MOC: 0.5325\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4030 - MOC: 0.6163 - val_loss: 0.4872 - val_MOC: 0.5377\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3938 - MOC: 0.6248 - val_loss: 0.4868 - val_MOC: 0.5382\n",
      "109\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5132 - MOC: 0.5129 - val_loss: 0.4784 - val_MOC: 0.5481\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4840 - MOC: 0.5412 - val_loss: 0.4792 - val_MOC: 0.5464\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4668 - MOC: 0.5573 - val_loss: 0.4801 - val_MOC: 0.5457\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4580 - MOC: 0.5656 - val_loss: 0.4790 - val_MOC: 0.5460\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 448us/step - loss: 0.4470 - MOC: 0.5757 - val_loss: 0.4722 - val_MOC: 0.5529\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4351 - MOC: 0.5868 - val_loss: 0.4762 - val_MOC: 0.5491\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4258 - MOC: 0.5954 - val_loss: 0.4808 - val_MOC: 0.5443\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4170 - MOC: 0.6035 - val_loss: 0.4794 - val_MOC: 0.5452\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4078 - MOC: 0.6120 - val_loss: 0.4810 - val_MOC: 0.5436\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4026 - MOC: 0.6167 - val_loss: 0.4799 - val_MOC: 0.5446\n",
      "110\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5131 - MOC: 0.5139 - val_loss: 0.4779 - val_MOC: 0.5489\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4867 - MOC: 0.5397 - val_loss: 0.4747 - val_MOC: 0.5511\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4714 - MOC: 0.5540 - val_loss: 0.4772 - val_MOC: 0.5481\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 442us/step - loss: 0.4595 - MOC: 0.5649 - val_loss: 0.4839 - val_MOC: 0.5416\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4486 - MOC: 0.5750 - val_loss: 0.4853 - val_MOC: 0.5397\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4417 - MOC: 0.5813 - val_loss: 0.4793 - val_MOC: 0.5470\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4311 - MOC: 0.5911 - val_loss: 0.4859 - val_MOC: 0.5395\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4218 - MOC: 0.5997 - val_loss: 0.4837 - val_MOC: 0.5416\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4116 - MOC: 0.6092 - val_loss: 0.4961 - val_MOC: 0.5284\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4032 - MOC: 0.6169 - val_loss: 0.5009 - val_MOC: 0.5239\n",
      "111\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.5115 - MOC: 0.5156 - val_loss: 0.4851 - val_MOC: 0.5415\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4855 - MOC: 0.5409 - val_loss: 0.4832 - val_MOC: 0.5425\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4689 - MOC: 0.5562 - val_loss: 0.4710 - val_MOC: 0.5558\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 448us/step - loss: 0.4596 - MOC: 0.5650 - val_loss: 0.4730 - val_MOC: 0.5533\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.4478 - MOC: 0.5758 - val_loss: 0.4810 - val_MOC: 0.5441\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4369 - MOC: 0.5857 - val_loss: 0.4818 - val_MOC: 0.5444\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4289 - MOC: 0.5932 - val_loss: 0.4805 - val_MOC: 0.5452\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4222 - MOC: 0.5994 - val_loss: 0.4839 - val_MOC: 0.5410\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4113 - MOC: 0.6093 - val_loss: 0.4832 - val_MOC: 0.5414\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4030 - MOC: 0.6169 - val_loss: 0.4903 - val_MOC: 0.5345\n",
      "112\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.5146 - MOC: 0.5131 - val_loss: 0.4836 - val_MOC: 0.5430\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4870 - MOC: 0.5398 - val_loss: 0.4830 - val_MOC: 0.5440\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4716 - MOC: 0.5542 - val_loss: 0.4840 - val_MOC: 0.5424\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.4588 - MOC: 0.5660 - val_loss: 0.4795 - val_MOC: 0.5472\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 408us/step - loss: 0.4488 - MOC: 0.5753 - val_loss: 0.4878 - val_MOC: 0.5390\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4400 - MOC: 0.5834 - val_loss: 0.4884 - val_MOC: 0.5376\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4309 - MOC: 0.5917 - val_loss: 0.4896 - val_MOC: 0.5363\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4242 - MOC: 0.5979 - val_loss: 0.4956 - val_MOC: 0.5306\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4157 - MOC: 0.6057 - val_loss: 0.4967 - val_MOC: 0.5292\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4074 - MOC: 0.6134 - val_loss: 0.5048 - val_MOC: 0.5206\n",
      "113\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.5118 - MOC: 0.5156 - val_loss: 0.4925 - val_MOC: 0.5347\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4838 - MOC: 0.5426 - val_loss: 0.4910 - val_MOC: 0.5358\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4700 - MOC: 0.5555 - val_loss: 0.4855 - val_MOC: 0.5408\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4598 - MOC: 0.5649 - val_loss: 0.4923 - val_MOC: 0.5339\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4483 - MOC: 0.5756 - val_loss: 0.4949 - val_MOC: 0.5310\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4368 - MOC: 0.5862 - val_loss: 0.4920 - val_MOC: 0.5342\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4278 - MOC: 0.5945 - val_loss: 0.4927 - val_MOC: 0.5333\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4175 - MOC: 0.6040 - val_loss: 0.5016 - val_MOC: 0.5241\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4119 - MOC: 0.6092 - val_loss: 0.4948 - val_MOC: 0.5308\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4038 - MOC: 0.6165 - val_loss: 0.4983 - val_MOC: 0.5274\n",
      "114\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 414us/step - loss: 0.5028 - MOC: 0.5222 - val_loss: 0.4925 - val_MOC: 0.5343\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4792 - MOC: 0.5451 - val_loss: 0.4865 - val_MOC: 0.5398\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4633 - MOC: 0.5599 - val_loss: 0.4818 - val_MOC: 0.5449\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4524 - MOC: 0.5701 - val_loss: 0.4878 - val_MOC: 0.5382\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4414 - MOC: 0.5803 - val_loss: 0.4866 - val_MOC: 0.5394\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4308 - MOC: 0.5903 - val_loss: 0.4909 - val_MOC: 0.5349\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4217 - MOC: 0.5985 - val_loss: 0.4899 - val_MOC: 0.5365\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4129 - MOC: 0.6068 - val_loss: 0.4895 - val_MOC: 0.5365\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4053 - MOC: 0.6138 - val_loss: 0.4921 - val_MOC: 0.5337\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3952 - MOC: 0.6231 - val_loss: 0.5067 - val_MOC: 0.5181\n",
      "115\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 447us/step - loss: 0.5098 - MOC: 0.5172 - val_loss: 0.4906 - val_MOC: 0.5366\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4878 - MOC: 0.5386 - val_loss: 0.4924 - val_MOC: 0.5338\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4700 - MOC: 0.5554 - val_loss: 0.4864 - val_MOC: 0.5409\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4596 - MOC: 0.5651 - val_loss: 0.4947 - val_MOC: 0.5311\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4483 - MOC: 0.5755 - val_loss: 0.4926 - val_MOC: 0.5334\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4384 - MOC: 0.5847 - val_loss: 0.4907 - val_MOC: 0.5363\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4292 - MOC: 0.5932 - val_loss: 0.4944 - val_MOC: 0.5321\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4204 - MOC: 0.6011 - val_loss: 0.4945 - val_MOC: 0.5320\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4122 - MOC: 0.6089 - val_loss: 0.5017 - val_MOC: 0.5237\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4054 - MOC: 0.6151 - val_loss: 0.5009 - val_MOC: 0.5251\n",
      "116\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.5100 - MOC: 0.5168 - val_loss: 0.4980 - val_MOC: 0.5297\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4824 - MOC: 0.5437 - val_loss: 0.4888 - val_MOC: 0.5384\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4653 - MOC: 0.5598 - val_loss: 0.4871 - val_MOC: 0.5401\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4557 - MOC: 0.5685 - val_loss: 0.4846 - val_MOC: 0.5423\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.4441 - MOC: 0.5794 - val_loss: 0.4915 - val_MOC: 0.5351\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.4358 - MOC: 0.5869 - val_loss: 0.4894 - val_MOC: 0.5374\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4257 - MOC: 0.5962 - val_loss: 0.4907 - val_MOC: 0.5360\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4150 - MOC: 0.6062 - val_loss: 0.4916 - val_MOC: 0.5345\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4089 - MOC: 0.6117 - val_loss: 0.4941 - val_MOC: 0.5323\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4003 - MOC: 0.6198 - val_loss: 0.4941 - val_MOC: 0.5325\n",
      "117\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5062 - MOC: 0.5205 - val_loss: 0.4828 - val_MOC: 0.5443\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4818 - MOC: 0.5440 - val_loss: 0.4813 - val_MOC: 0.5451\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4658 - MOC: 0.5591 - val_loss: 0.4891 - val_MOC: 0.5367\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4547 - MOC: 0.5694 - val_loss: 0.4843 - val_MOC: 0.5419\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 443us/step - loss: 0.4443 - MOC: 0.5789 - val_loss: 0.4829 - val_MOC: 0.5434\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4342 - MOC: 0.5884 - val_loss: 0.4910 - val_MOC: 0.5342\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4244 - MOC: 0.5973 - val_loss: 0.4871 - val_MOC: 0.5392\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4171 - MOC: 0.6040 - val_loss: 0.4932 - val_MOC: 0.5323\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4071 - MOC: 0.6133 - val_loss: 0.4983 - val_MOC: 0.5270\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4029 - MOC: 0.6172 - val_loss: 0.4904 - val_MOC: 0.5355\n",
      "118\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5164 - MOC: 0.5102 - val_loss: 0.4916 - val_MOC: 0.5353\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4901 - MOC: 0.5356 - val_loss: 0.4877 - val_MOC: 0.5387\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4746 - MOC: 0.5501 - val_loss: 0.4916 - val_MOC: 0.5360\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.4616 - MOC: 0.5624 - val_loss: 0.4881 - val_MOC: 0.5380\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.4524 - MOC: 0.5706 - val_loss: 0.4932 - val_MOC: 0.5331\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4396 - MOC: 0.5824 - val_loss: 0.4963 - val_MOC: 0.5300\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4320 - MOC: 0.5895 - val_loss: 0.4938 - val_MOC: 0.5330\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4241 - MOC: 0.5969 - val_loss: 0.4965 - val_MOC: 0.5292\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4148 - MOC: 0.6055 - val_loss: 0.5022 - val_MOC: 0.5241\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4087 - MOC: 0.6111 - val_loss: 0.5070 - val_MOC: 0.5184\n",
      "119\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5044 - MOC: 0.5203 - val_loss: 0.4957 - val_MOC: 0.5312\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4782 - MOC: 0.5457 - val_loss: 0.4896 - val_MOC: 0.5373\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4630 - MOC: 0.5601 - val_loss: 0.4888 - val_MOC: 0.5378\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 455us/step - loss: 0.4498 - MOC: 0.5725 - val_loss: 0.4874 - val_MOC: 0.5393\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.4374 - MOC: 0.5838 - val_loss: 0.4840 - val_MOC: 0.5423\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4314 - MOC: 0.5894 - val_loss: 0.4899 - val_MOC: 0.5360\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4209 - MOC: 0.5991 - val_loss: 0.4974 - val_MOC: 0.5275\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4095 - MOC: 0.6097 - val_loss: 0.4947 - val_MOC: 0.5324\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4024 - MOC: 0.6164 - val_loss: 0.4896 - val_MOC: 0.5354\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3959 - MOC: 0.6223 - val_loss: 0.4942 - val_MOC: 0.5311\n",
      "120\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 429us/step - loss: 0.5074 - MOC: 0.5200 - val_loss: 0.4810 - val_MOC: 0.5459\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4796 - MOC: 0.5469 - val_loss: 0.4817 - val_MOC: 0.5447\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4677 - MOC: 0.5578 - val_loss: 0.4761 - val_MOC: 0.5511\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4554 - MOC: 0.5694 - val_loss: 0.4822 - val_MOC: 0.5441\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4462 - MOC: 0.5779 - val_loss: 0.4847 - val_MOC: 0.5415\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4347 - MOC: 0.5884 - val_loss: 0.4873 - val_MOC: 0.5388\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4287 - MOC: 0.5939 - val_loss: 0.4833 - val_MOC: 0.5433\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4186 - MOC: 0.6033 - val_loss: 0.4860 - val_MOC: 0.5396\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4101 - MOC: 0.6112 - val_loss: 0.4861 - val_MOC: 0.5393\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4040 - MOC: 0.6166 - val_loss: 0.4925 - val_MOC: 0.5326\n",
      "121\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 411us/step - loss: 0.5026 - MOC: 0.5225 - val_loss: 0.4811 - val_MOC: 0.5456\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4809 - MOC: 0.5436 - val_loss: 0.4748 - val_MOC: 0.5523\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4645 - MOC: 0.5591 - val_loss: 0.4755 - val_MOC: 0.5507\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4516 - MOC: 0.5712 - val_loss: 0.4819 - val_MOC: 0.5440\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4399 - MOC: 0.5820 - val_loss: 0.4855 - val_MOC: 0.5398\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4289 - MOC: 0.5922 - val_loss: 0.4798 - val_MOC: 0.5466\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4222 - MOC: 0.5983 - val_loss: 0.4809 - val_MOC: 0.5449\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 463us/step - loss: 0.4160 - MOC: 0.6041 - val_loss: 0.4928 - val_MOC: 0.5319\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4043 - MOC: 0.6150 - val_loss: 0.4885 - val_MOC: 0.5370\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.3990 - MOC: 0.6198 - val_loss: 0.4936 - val_MOC: 0.5310\n",
      "122\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 406us/step - loss: 0.5030 - MOC: 0.5233 - val_loss: 0.4791 - val_MOC: 0.5469\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4790 - MOC: 0.5469 - val_loss: 0.4758 - val_MOC: 0.5505\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4645 - MOC: 0.5603 - val_loss: 0.4765 - val_MOC: 0.5498\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4540 - MOC: 0.5702 - val_loss: 0.4819 - val_MOC: 0.5442\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4410 - MOC: 0.5822 - val_loss: 0.4785 - val_MOC: 0.5472\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4328 - MOC: 0.5898 - val_loss: 0.4783 - val_MOC: 0.5476\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4224 - MOC: 0.5994 - val_loss: 0.4813 - val_MOC: 0.5437\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4170 - MOC: 0.6044 - val_loss: 0.4842 - val_MOC: 0.5415\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 2s 434us/step - loss: 0.4077 - MOC: 0.6129 - val_loss: 0.4862 - val_MOC: 0.5397\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.3997 - MOC: 0.6202 - val_loss: 0.4861 - val_MOC: 0.5393\n",
      "123\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5096 - MOC: 0.5161 - val_loss: 0.4767 - val_MOC: 0.5508\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4857 - MOC: 0.5394 - val_loss: 0.4810 - val_MOC: 0.5452\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 397us/step - loss: 0.4706 - MOC: 0.5535 - val_loss: 0.4765 - val_MOC: 0.5492\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4609 - MOC: 0.5624 - val_loss: 0.4761 - val_MOC: 0.5502\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4485 - MOC: 0.5740 - val_loss: 0.4787 - val_MOC: 0.5473\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4403 - MOC: 0.5815 - val_loss: 0.4838 - val_MOC: 0.5420\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4294 - MOC: 0.5917 - val_loss: 0.4901 - val_MOC: 0.5351\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 421us/step - loss: 0.4206 - MOC: 0.5996 - val_loss: 0.4877 - val_MOC: 0.5375\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4139 - MOC: 0.6060 - val_loss: 0.4882 - val_MOC: 0.5372\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4039 - MOC: 0.6152 - val_loss: 0.4897 - val_MOC: 0.5358\n",
      "124\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.5098 - MOC: 0.5163 - val_loss: 0.4838 - val_MOC: 0.5435\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4872 - MOC: 0.5384 - val_loss: 0.4829 - val_MOC: 0.5439\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4711 - MOC: 0.5536 - val_loss: 0.4839 - val_MOC: 0.5422\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.4579 - MOC: 0.5660 - val_loss: 0.4847 - val_MOC: 0.5417\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 451us/step - loss: 0.4473 - MOC: 0.5757 - val_loss: 0.4839 - val_MOC: 0.5420\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4366 - MOC: 0.5857 - val_loss: 0.4875 - val_MOC: 0.5381\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4294 - MOC: 0.5922 - val_loss: 0.4943 - val_MOC: 0.5315\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4223 - MOC: 0.5985 - val_loss: 0.4938 - val_MOC: 0.5316\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4145 - MOC: 0.6059 - val_loss: 0.4899 - val_MOC: 0.5363\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4057 - MOC: 0.6141 - val_loss: 0.4991 - val_MOC: 0.5260\n",
      "125\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 451us/step - loss: 0.5116 - MOC: 0.5151 - val_loss: 0.4815 - val_MOC: 0.5455\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4840 - MOC: 0.5419 - val_loss: 0.4792 - val_MOC: 0.5478\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4693 - MOC: 0.5556 - val_loss: 0.4789 - val_MOC: 0.5471\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4560 - MOC: 0.5678 - val_loss: 0.4815 - val_MOC: 0.5444\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4452 - MOC: 0.5781 - val_loss: 0.4815 - val_MOC: 0.5441\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4375 - MOC: 0.5850 - val_loss: 0.4818 - val_MOC: 0.5439\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4270 - MOC: 0.5948 - val_loss: 0.4806 - val_MOC: 0.5451\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4176 - MOC: 0.6033 - val_loss: 0.4833 - val_MOC: 0.5423\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4085 - MOC: 0.6118 - val_loss: 0.4895 - val_MOC: 0.5354\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4010 - MOC: 0.6188 - val_loss: 0.4847 - val_MOC: 0.5408\n",
      "126\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 434us/step - loss: 0.5012 - MOC: 0.5248 - val_loss: 0.4877 - val_MOC: 0.5393\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4756 - MOC: 0.5496 - val_loss: 0.4822 - val_MOC: 0.5442\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4624 - MOC: 0.5618 - val_loss: 0.4837 - val_MOC: 0.5420\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4492 - MOC: 0.5742 - val_loss: 0.4802 - val_MOC: 0.5460\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4414 - MOC: 0.5814 - val_loss: 0.4914 - val_MOC: 0.5337\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4301 - MOC: 0.5918 - val_loss: 0.4810 - val_MOC: 0.5448\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4202 - MOC: 0.6010 - val_loss: 0.4833 - val_MOC: 0.5422\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 377us/step - loss: 0.4125 - MOC: 0.6081 - val_loss: 0.4902 - val_MOC: 0.5342\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4046 - MOC: 0.6154 - val_loss: 0.4876 - val_MOC: 0.5374\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.3984 - MOC: 0.6210 - val_loss: 0.4872 - val_MOC: 0.5389\n",
      "127\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 430us/step - loss: 0.5100 - MOC: 0.5172 - val_loss: 0.4815 - val_MOC: 0.5446\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4841 - MOC: 0.5420 - val_loss: 0.4762 - val_MOC: 0.5498\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 378us/step - loss: 0.4688 - MOC: 0.5564 - val_loss: 0.4807 - val_MOC: 0.5447\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4588 - MOC: 0.5654 - val_loss: 0.4755 - val_MOC: 0.5506\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4479 - MOC: 0.5756 - val_loss: 0.4789 - val_MOC: 0.5465\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4389 - MOC: 0.5839 - val_loss: 0.4820 - val_MOC: 0.5426\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4288 - MOC: 0.5931 - val_loss: 0.4797 - val_MOC: 0.5452\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4211 - MOC: 0.6004 - val_loss: 0.4826 - val_MOC: 0.5415\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4125 - MOC: 0.6082 - val_loss: 0.4814 - val_MOC: 0.5432\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 2s 417us/step - loss: 0.4066 - MOC: 0.6134 - val_loss: 0.4887 - val_MOC: 0.5353\n",
      "128\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 406us/step - loss: 0.5101 - MOC: 0.5157 - val_loss: 0.4871 - val_MOC: 0.5392\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4849 - MOC: 0.5405 - val_loss: 0.4762 - val_MOC: 0.5501\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4700 - MOC: 0.5545 - val_loss: 0.4763 - val_MOC: 0.5494\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4573 - MOC: 0.5662 - val_loss: 0.4739 - val_MOC: 0.5525\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4477 - MOC: 0.5752 - val_loss: 0.4757 - val_MOC: 0.5511\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 441us/step - loss: 0.4385 - MOC: 0.5837 - val_loss: 0.4780 - val_MOC: 0.5478\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.4297 - MOC: 0.5918 - val_loss: 0.4843 - val_MOC: 0.5413\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4231 - MOC: 0.5979 - val_loss: 0.4792 - val_MOC: 0.5461\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4130 - MOC: 0.6073 - val_loss: 0.4852 - val_MOC: 0.5396\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4056 - MOC: 0.6141 - val_loss: 0.4883 - val_MOC: 0.5370\n",
      "129\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.5107 - MOC: 0.5168 - val_loss: 0.4781 - val_MOC: 0.5482\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4862 - MOC: 0.5406 - val_loss: 0.4865 - val_MOC: 0.5389\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4721 - MOC: 0.5537 - val_loss: 0.4764 - val_MOC: 0.5505\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4594 - MOC: 0.5656 - val_loss: 0.4777 - val_MOC: 0.5486\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 420us/step - loss: 0.4506 - MOC: 0.5736 - val_loss: 0.4767 - val_MOC: 0.5502\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4408 - MOC: 0.5826 - val_loss: 0.4837 - val_MOC: 0.5416\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4303 - MOC: 0.5923 - val_loss: 0.4856 - val_MOC: 0.5405\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4224 - MOC: 0.5995 - val_loss: 0.4919 - val_MOC: 0.5344\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4148 - MOC: 0.6066 - val_loss: 0.4911 - val_MOC: 0.5348\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4063 - MOC: 0.6143 - val_loss: 0.4978 - val_MOC: 0.5275\n",
      "130\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5019 - MOC: 0.5243 - val_loss: 0.4846 - val_MOC: 0.5429\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4765 - MOC: 0.5486 - val_loss: 0.4885 - val_MOC: 0.5376\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4602 - MOC: 0.5638 - val_loss: 0.4799 - val_MOC: 0.5467\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 452us/step - loss: 0.4515 - MOC: 0.5720 - val_loss: 0.4748 - val_MOC: 0.5523\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.4399 - MOC: 0.5827 - val_loss: 0.4836 - val_MOC: 0.5421\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4293 - MOC: 0.5926 - val_loss: 0.4918 - val_MOC: 0.5334\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4203 - MOC: 0.6009 - val_loss: 0.4906 - val_MOC: 0.5343\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4116 - MOC: 0.6088 - val_loss: 0.4863 - val_MOC: 0.5390\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4048 - MOC: 0.6153 - val_loss: 0.4904 - val_MOC: 0.5344\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.3990 - MOC: 0.6206 - val_loss: 0.4882 - val_MOC: 0.5371\n",
      "131\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.5079 - MOC: 0.5190 - val_loss: 0.4790 - val_MOC: 0.5484\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4845 - MOC: 0.5419 - val_loss: 0.4780 - val_MOC: 0.5490\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4672 - MOC: 0.5581 - val_loss: 0.4771 - val_MOC: 0.5491\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4571 - MOC: 0.5673 - val_loss: 0.4790 - val_MOC: 0.5473\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4462 - MOC: 0.5775 - val_loss: 0.4775 - val_MOC: 0.5481\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4363 - MOC: 0.5866 - val_loss: 0.4869 - val_MOC: 0.5386\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4271 - MOC: 0.5952 - val_loss: 0.4838 - val_MOC: 0.5417\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4195 - MOC: 0.6021 - val_loss: 0.4851 - val_MOC: 0.5396\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4098 - MOC: 0.6112 - val_loss: 0.4845 - val_MOC: 0.5404\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 403us/step - loss: 0.4041 - MOC: 0.6163 - val_loss: 0.4914 - val_MOC: 0.5333\n",
      "132\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 410us/step - loss: 0.5056 - MOC: 0.5206 - val_loss: 0.4789 - val_MOC: 0.5479\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4806 - MOC: 0.5448 - val_loss: 0.4711 - val_MOC: 0.5554\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4673 - MOC: 0.5573 - val_loss: 0.4733 - val_MOC: 0.5518\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4569 - MOC: 0.5669 - val_loss: 0.4727 - val_MOC: 0.5535\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4458 - MOC: 0.5772 - val_loss: 0.4755 - val_MOC: 0.5517\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 457us/step - loss: 0.4379 - MOC: 0.5843 - val_loss: 0.4769 - val_MOC: 0.5489\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4289 - MOC: 0.5927 - val_loss: 0.4843 - val_MOC: 0.5406\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4184 - MOC: 0.6026 - val_loss: 0.4885 - val_MOC: 0.5364\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4127 - MOC: 0.6076 - val_loss: 0.4818 - val_MOC: 0.5440\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4055 - MOC: 0.6143 - val_loss: 0.4866 - val_MOC: 0.5391\n",
      "133\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.5085 - MOC: 0.5182 - val_loss: 0.4785 - val_MOC: 0.5485\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4868 - MOC: 0.5394 - val_loss: 0.4758 - val_MOC: 0.5507\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4717 - MOC: 0.5534 - val_loss: 0.4836 - val_MOC: 0.5425\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4607 - MOC: 0.5635 - val_loss: 0.4812 - val_MOC: 0.5447\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 417us/step - loss: 0.4493 - MOC: 0.5742 - val_loss: 0.4789 - val_MOC: 0.5472\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4409 - MOC: 0.5818 - val_loss: 0.4895 - val_MOC: 0.5364\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4314 - MOC: 0.5907 - val_loss: 0.4872 - val_MOC: 0.5386\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4240 - MOC: 0.5975 - val_loss: 0.4842 - val_MOC: 0.5425\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4161 - MOC: 0.6047 - val_loss: 0.4891 - val_MOC: 0.5377\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4098 - MOC: 0.6106 - val_loss: 0.4885 - val_MOC: 0.5373\n",
      "134\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5045 - MOC: 0.5213 - val_loss: 0.4823 - val_MOC: 0.5450\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4807 - MOC: 0.5447 - val_loss: 0.4820 - val_MOC: 0.5446\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4661 - MOC: 0.5582 - val_loss: 0.4811 - val_MOC: 0.5453\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4534 - MOC: 0.5701 - val_loss: 0.4831 - val_MOC: 0.5432\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4430 - MOC: 0.5798 - val_loss: 0.4911 - val_MOC: 0.5341\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 414us/step - loss: 0.4334 - MOC: 0.5885 - val_loss: 0.4936 - val_MOC: 0.5320\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.4262 - MOC: 0.5952 - val_loss: 0.4933 - val_MOC: 0.5316\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4200 - MOC: 0.6009 - val_loss: 0.4951 - val_MOC: 0.5302\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4109 - MOC: 0.6092 - val_loss: 0.4918 - val_MOC: 0.5340\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4041 - MOC: 0.6156 - val_loss: 0.4952 - val_MOC: 0.5301\n",
      "135\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 405us/step - loss: 0.5044 - MOC: 0.5220 - val_loss: 0.4799 - val_MOC: 0.5480\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4820 - MOC: 0.5439 - val_loss: 0.4787 - val_MOC: 0.5481\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4676 - MOC: 0.5574 - val_loss: 0.4856 - val_MOC: 0.5405\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4529 - MOC: 0.5711 - val_loss: 0.4814 - val_MOC: 0.5451\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4433 - MOC: 0.5800 - val_loss: 0.4829 - val_MOC: 0.5432\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4330 - MOC: 0.5894 - val_loss: 0.4852 - val_MOC: 0.5407\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4236 - MOC: 0.5981 - val_loss: 0.4917 - val_MOC: 0.5342\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 420us/step - loss: 0.4153 - MOC: 0.6057 - val_loss: 0.4867 - val_MOC: 0.5396\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4117 - MOC: 0.6091 - val_loss: 0.4973 - val_MOC: 0.5273\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4045 - MOC: 0.6156 - val_loss: 0.4919 - val_MOC: 0.5340\n",
      "136\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5051 - MOC: 0.5218 - val_loss: 0.4803 - val_MOC: 0.5461\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4803 - MOC: 0.5459 - val_loss: 0.4778 - val_MOC: 0.5491\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4662 - MOC: 0.5589 - val_loss: 0.4745 - val_MOC: 0.5519\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4539 - MOC: 0.5704 - val_loss: 0.4756 - val_MOC: 0.5502\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4442 - MOC: 0.5794 - val_loss: 0.4757 - val_MOC: 0.5502\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4361 - MOC: 0.5867 - val_loss: 0.4738 - val_MOC: 0.5516\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4244 - MOC: 0.5976 - val_loss: 0.4850 - val_MOC: 0.5400\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 2s 446us/step - loss: 0.4185 - MOC: 0.6031 - val_loss: 0.4830 - val_MOC: 0.5415\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4113 - MOC: 0.6096 - val_loss: 0.4830 - val_MOC: 0.5421\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4021 - MOC: 0.6181 - val_loss: 0.4955 - val_MOC: 0.5287\n",
      "137\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.5086 - MOC: 0.5170 - val_loss: 0.4834 - val_MOC: 0.5436\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4827 - MOC: 0.5424 - val_loss: 0.4809 - val_MOC: 0.5455\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4685 - MOC: 0.5556 - val_loss: 0.4792 - val_MOC: 0.5469\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4558 - MOC: 0.5676 - val_loss: 0.4826 - val_MOC: 0.5430\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 396us/step - loss: 0.4478 - MOC: 0.5749 - val_loss: 0.4862 - val_MOC: 0.5392\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 2s 454us/step - loss: 0.4377 - MOC: 0.5841 - val_loss: 0.4827 - val_MOC: 0.5438\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4299 - MOC: 0.5916 - val_loss: 0.4846 - val_MOC: 0.5406\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4210 - MOC: 0.5999 - val_loss: 0.4867 - val_MOC: 0.5389\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4132 - MOC: 0.6069 - val_loss: 0.4888 - val_MOC: 0.5368\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4047 - MOC: 0.6147 - val_loss: 0.4896 - val_MOC: 0.5355\n",
      "138\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5047 - MOC: 0.5220 - val_loss: 0.4824 - val_MOC: 0.5436\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4817 - MOC: 0.5444 - val_loss: 0.4721 - val_MOC: 0.5543\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4674 - MOC: 0.5578 - val_loss: 0.4715 - val_MOC: 0.5544\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4547 - MOC: 0.5696 - val_loss: 0.4704 - val_MOC: 0.5555\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 2s 497us/step - loss: 0.4457 - MOC: 0.5779 - val_loss: 0.4777 - val_MOC: 0.5481\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 415us/step - loss: 0.4369 - MOC: 0.5859 - val_loss: 0.4740 - val_MOC: 0.5515\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4278 - MOC: 0.5944 - val_loss: 0.4763 - val_MOC: 0.5491\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4203 - MOC: 0.6011 - val_loss: 0.4807 - val_MOC: 0.5444\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4131 - MOC: 0.6079 - val_loss: 0.4823 - val_MOC: 0.5423\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4075 - MOC: 0.6130 - val_loss: 0.4822 - val_MOC: 0.5427\n",
      "139\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 437us/step - loss: 0.5017 - MOC: 0.5243 - val_loss: 0.4749 - val_MOC: 0.5520\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4807 - MOC: 0.5448 - val_loss: 0.4834 - val_MOC: 0.5423\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4681 - MOC: 0.5566 - val_loss: 0.4854 - val_MOC: 0.5401\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4540 - MOC: 0.5697 - val_loss: 0.4778 - val_MOC: 0.5487\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 391us/step - loss: 0.4422 - MOC: 0.5808 - val_loss: 0.4845 - val_MOC: 0.5413\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4349 - MOC: 0.5874 - val_loss: 0.4873 - val_MOC: 0.5385\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4235 - MOC: 0.5981 - val_loss: 0.4806 - val_MOC: 0.5455\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4167 - MOC: 0.6043 - val_loss: 0.4873 - val_MOC: 0.5387\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4083 - MOC: 0.6119 - val_loss: 0.4842 - val_MOC: 0.5413\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 392us/step - loss: 0.4028 - MOC: 0.6169 - val_loss: 0.4908 - val_MOC: 0.5343\n",
      "140\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 469us/step - loss: 0.5076 - MOC: 0.5184 - val_loss: 0.4860 - val_MOC: 0.5403\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 393us/step - loss: 0.4812 - MOC: 0.5438 - val_loss: 0.4786 - val_MOC: 0.5481\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4660 - MOC: 0.5583 - val_loss: 0.4801 - val_MOC: 0.5459\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4541 - MOC: 0.5693 - val_loss: 0.4797 - val_MOC: 0.5464\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4436 - MOC: 0.5790 - val_loss: 0.4840 - val_MOC: 0.5410\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4360 - MOC: 0.5859 - val_loss: 0.4804 - val_MOC: 0.5450\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4274 - MOC: 0.5939 - val_loss: 0.4801 - val_MOC: 0.5454\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4210 - MOC: 0.5999 - val_loss: 0.4820 - val_MOC: 0.5439\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 2s 419us/step - loss: 0.4128 - MOC: 0.6074 - val_loss: 0.4862 - val_MOC: 0.5395\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 399us/step - loss: 0.4032 - MOC: 0.6162 - val_loss: 0.4850 - val_MOC: 0.5405\n",
      "141\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 395us/step - loss: 0.5047 - MOC: 0.5208 - val_loss: 0.4793 - val_MOC: 0.5470\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4801 - MOC: 0.5448 - val_loss: 0.4781 - val_MOC: 0.5481\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4668 - MOC: 0.5570 - val_loss: 0.4798 - val_MOC: 0.5465\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4557 - MOC: 0.5675 - val_loss: 0.4723 - val_MOC: 0.5535\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4451 - MOC: 0.5774 - val_loss: 0.4831 - val_MOC: 0.5418\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 389us/step - loss: 0.4350 - MOC: 0.5866 - val_loss: 0.4789 - val_MOC: 0.5463\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 416us/step - loss: 0.4273 - MOC: 0.5937 - val_loss: 0.4777 - val_MOC: 0.5483\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4168 - MOC: 0.6035 - val_loss: 0.4774 - val_MOC: 0.5478\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4128 - MOC: 0.6072 - val_loss: 0.4875 - val_MOC: 0.5379\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4039 - MOC: 0.6153 - val_loss: 0.4882 - val_MOC: 0.5359\n",
      "142\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 400us/step - loss: 0.4985 - MOC: 0.5283 - val_loss: 0.4789 - val_MOC: 0.5468\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4762 - MOC: 0.5498 - val_loss: 0.4771 - val_MOC: 0.5487\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 401us/step - loss: 0.4628 - MOC: 0.5623 - val_loss: 0.4764 - val_MOC: 0.5501\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 418us/step - loss: 0.4506 - MOC: 0.5738 - val_loss: 0.4816 - val_MOC: 0.5434\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4396 - MOC: 0.5838 - val_loss: 0.4774 - val_MOC: 0.5484\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4332 - MOC: 0.5897 - val_loss: 0.4793 - val_MOC: 0.5460\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4257 - MOC: 0.5967 - val_loss: 0.4831 - val_MOC: 0.5420\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4142 - MOC: 0.6072 - val_loss: 0.4801 - val_MOC: 0.5452\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4103 - MOC: 0.6109 - val_loss: 0.4842 - val_MOC: 0.5409\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4015 - MOC: 0.6189 - val_loss: 0.4858 - val_MOC: 0.5393\n",
      "143\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 444us/step - loss: 0.4980 - MOC: 0.5275 - val_loss: 0.4854 - val_MOC: 0.5404\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4734 - MOC: 0.5513 - val_loss: 0.4782 - val_MOC: 0.5475\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4597 - MOC: 0.5642 - val_loss: 0.4793 - val_MOC: 0.5463\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4481 - MOC: 0.5749 - val_loss: 0.4761 - val_MOC: 0.5493\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4382 - MOC: 0.5842 - val_loss: 0.4832 - val_MOC: 0.5416\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4300 - MOC: 0.5916 - val_loss: 0.4750 - val_MOC: 0.5505\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4198 - MOC: 0.6013 - val_loss: 0.4811 - val_MOC: 0.5438\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4111 - MOC: 0.6091 - val_loss: 0.4813 - val_MOC: 0.5435\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4047 - MOC: 0.6152 - val_loss: 0.4831 - val_MOC: 0.5415\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.3968 - MOC: 0.6225 - val_loss: 0.4819 - val_MOC: 0.5427\n",
      "144\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 431us/step - loss: 0.5092 - MOC: 0.5182 - val_loss: 0.4880 - val_MOC: 0.5373\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.4882 - MOC: 0.5385 - val_loss: 0.4706 - val_MOC: 0.5560\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4729 - MOC: 0.5529 - val_loss: 0.4778 - val_MOC: 0.5482\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4615 - MOC: 0.5635 - val_loss: 0.4849 - val_MOC: 0.5404\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4512 - MOC: 0.5730 - val_loss: 0.4838 - val_MOC: 0.5416\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4419 - MOC: 0.5816 - val_loss: 0.4865 - val_MOC: 0.5385\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4322 - MOC: 0.5905 - val_loss: 0.4856 - val_MOC: 0.5394\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4237 - MOC: 0.5983 - val_loss: 0.4869 - val_MOC: 0.5383\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4183 - MOC: 0.6033 - val_loss: 0.4954 - val_MOC: 0.5292\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4092 - MOC: 0.6116 - val_loss: 0.4884 - val_MOC: 0.5373\n",
      "145\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 2s 427us/step - loss: 0.5056 - MOC: 0.5208 - val_loss: 0.4854 - val_MOC: 0.5411\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4821 - MOC: 0.5435 - val_loss: 0.4795 - val_MOC: 0.5470\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4670 - MOC: 0.5578 - val_loss: 0.4794 - val_MOC: 0.5468\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 384us/step - loss: 0.4576 - MOC: 0.5663 - val_loss: 0.4771 - val_MOC: 0.5489\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4467 - MOC: 0.5765 - val_loss: 0.4759 - val_MOC: 0.5500\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4370 - MOC: 0.5853 - val_loss: 0.4833 - val_MOC: 0.5430\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4287 - MOC: 0.5932 - val_loss: 0.4851 - val_MOC: 0.5399\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 379us/step - loss: 0.4214 - MOC: 0.5997 - val_loss: 0.4825 - val_MOC: 0.5438\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4146 - MOC: 0.6061 - val_loss: 0.4848 - val_MOC: 0.5405\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4066 - MOC: 0.6135 - val_loss: 0.4825 - val_MOC: 0.5434\n",
      "146\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.5035 - MOC: 0.5225 - val_loss: 0.4847 - val_MOC: 0.5419\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4802 - MOC: 0.5453 - val_loss: 0.4798 - val_MOC: 0.5464\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4670 - MOC: 0.5576 - val_loss: 0.4760 - val_MOC: 0.5500\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4562 - MOC: 0.5676 - val_loss: 0.4756 - val_MOC: 0.5509\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4473 - MOC: 0.5758 - val_loss: 0.4779 - val_MOC: 0.5479\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 381us/step - loss: 0.4370 - MOC: 0.5854 - val_loss: 0.4688 - val_MOC: 0.5576\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4287 - MOC: 0.5930 - val_loss: 0.4768 - val_MOC: 0.5481\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 404us/step - loss: 0.4207 - MOC: 0.6004 - val_loss: 0.4849 - val_MOC: 0.5396\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 409us/step - loss: 0.4130 - MOC: 0.6074 - val_loss: 0.4886 - val_MOC: 0.5361\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4055 - MOC: 0.6144 - val_loss: 0.4844 - val_MOC: 0.5410\n",
      "147\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 402us/step - loss: 0.4987 - MOC: 0.5279 - val_loss: 0.4849 - val_MOC: 0.5408\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 390us/step - loss: 0.4774 - MOC: 0.5485 - val_loss: 0.4766 - val_MOC: 0.5492\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 398us/step - loss: 0.4622 - MOC: 0.5628 - val_loss: 0.4734 - val_MOC: 0.5524\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 2s 459us/step - loss: 0.4502 - MOC: 0.5738 - val_loss: 0.4739 - val_MOC: 0.5514\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4389 - MOC: 0.5843 - val_loss: 0.4850 - val_MOC: 0.5399\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4321 - MOC: 0.5906 - val_loss: 0.4771 - val_MOC: 0.5480\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4220 - MOC: 0.5998 - val_loss: 0.4814 - val_MOC: 0.5437\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 387us/step - loss: 0.4138 - MOC: 0.6074 - val_loss: 0.4790 - val_MOC: 0.5460\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 386us/step - loss: 0.4048 - MOC: 0.6157 - val_loss: 0.4934 - val_MOC: 0.5308\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 394us/step - loss: 0.3999 - MOC: 0.6202 - val_loss: 0.4901 - val_MOC: 0.5338\n",
      "148\n",
      "Train on 3600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "3600/3600 [==============================] - 1s 413us/step - loss: 0.5046 - MOC: 0.5225 - val_loss: 0.4790 - val_MOC: 0.5466\n",
      "Epoch 2/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4802 - MOC: 0.5462 - val_loss: 0.4743 - val_MOC: 0.5514\n",
      "Epoch 3/10\n",
      "3600/3600 [==============================] - 1s 380us/step - loss: 0.4667 - MOC: 0.5589 - val_loss: 0.4688 - val_MOC: 0.5573\n",
      "Epoch 4/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4540 - MOC: 0.5706 - val_loss: 0.4688 - val_MOC: 0.5574\n",
      "Epoch 5/10\n",
      "3600/3600 [==============================] - 1s 388us/step - loss: 0.4426 - MOC: 0.5812 - val_loss: 0.4696 - val_MOC: 0.5562\n",
      "Epoch 6/10\n",
      "3600/3600 [==============================] - 1s 385us/step - loss: 0.4355 - MOC: 0.5877 - val_loss: 0.4677 - val_MOC: 0.5576\n",
      "Epoch 7/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4268 - MOC: 0.5958 - val_loss: 0.4819 - val_MOC: 0.5424\n",
      "Epoch 8/10\n",
      "3600/3600 [==============================] - 1s 383us/step - loss: 0.4175 - MOC: 0.6044 - val_loss: 0.4763 - val_MOC: 0.5487\n",
      "Epoch 9/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4122 - MOC: 0.6092 - val_loss: 0.4827 - val_MOC: 0.5420\n",
      "Epoch 10/10\n",
      "3600/3600 [==============================] - 1s 382us/step - loss: 0.4035 - MOC: 0.6172 - val_loss: 0.4801 - val_MOC: 0.5450\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(2,150):\n",
    "    #ytr = np.abs(0.05*np.random.randn(Y.shape[0],Y.shape[1],Y.shape[2]))\n",
    "    #Y1 = Y +ytr\n",
    "    prGen = subprocess.Popen('./generatemore.sh')\n",
    "    historys[i] = model.fit(X,Y, batch_size = 100, epochs = 10,\n",
    "                           validation_data = (Xdev,Ydev),verbose=1)\n",
    "    model.save(\"/mnt/data/synthetic/deepsofi_v2_t_\"+str(i//10).zfill(4)+\".h5\")\n",
    "    print(i)\n",
    "    prGen.wait()\n",
    "    X,Y = readdata(nframes,n=900,magn=4,repeat = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i0 = len(history.history['val_MOC'])\n",
    "plt.plot(history.history['val_MOC'])\n",
    "for i in range(150):\n",
    "    vMOC = historys[i].history['val_MOC']\n",
    "    t = np.arange(len(vMOC))+i0\n",
    "    plt.plot(t,vMOC,'C0')\n",
    "    i0 = t[-1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ed7bb5780>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = randint(100)\n",
    "Ft, Ot4 = Xdev[i,:],Ydev[i,:]\n",
    "pOt4 = model.predict(Ft.reshape(1,Ft.shape[0],Ft.shape[1],Ft.shape[2],1))\n",
    "fig = plt.figure(figsize=(14,5))\n",
    "gs = mpl.gridspec.GridSpec(8, 16 , wspace=0., hspace=0.) # 2x3 grid\n",
    "Ft = np.squeeze(Ft)\n",
    "pOt4 = np.squeeze(pOt4)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[4:6,4:6]) # first full col\n",
    "ax1 = fig.add_subplot(gs[:4,8:]) # first row, second col\n",
    "ax2 = fig.add_subplot(gs[4:,8:])\n",
    "ax0.imshow(Ft.mean(axis=-1))\n",
    "ax1.imshow(Ot4+np.random.randn(40,40)*.02)\n",
    "ax2.imshow(pOt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pOt4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
